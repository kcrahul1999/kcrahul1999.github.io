---
title: "A Replication of Karlan and List (2007)"
author: "Rahul Kc"
date: today
callout-appearance: minimal # this hides the blue "i" icon on .callout-notes
---


## Introduction

Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the _American Economic Review_ in 2007. The article and supporting data are available from the [AEA website](https://www.aeaweb.org/articles?id=10.1257/aer.97.5.1774) and from Innovations for Poverty Action as part of [Harvard's Dataverse](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/27853&version=4.2).

In an effort to under stand "the economics of charity" Karlan and List found that a matching grant letter significantly boosts both revenue per solicitation and the likelihood of donationb by 19$ and 22$ respectively. The experiment itself, started by randomly assigning to either a control group or a matching grant treatment group, and within the matching grant treatment group individuals were randomly assigned to different matching grant rates, matching grant maximum amounts, and suggested donation amounts. 

Intrestingly larger matching ratios of $3:$1 and $2:$1 do not yield additional revenue when compared to the $1:$1 ratio. The study also considers spatial heterogeneity, finding that the influence of matching gifts varies significantly based on the political environment, with a stronger effect observed in red states that supported George W. Bush in the 2004 presidential election. This means that an individualâ€™s political beliefs has influences the level of giving, and their responsiveness to different treatments.

The researchers state that this study and previosuly similar conducted studies are all of course hypothetical. Therefore they state that the study might be viewed as a useful test of scope using an approach consistent with natural provision of a real public good. However despite variations in outcomes across studies, the researchers state that all studies convey the complexity of charitable giving behavior and the need for further empirical investigation.

This project seeks to replicate their results.

## Data

### Description

```{python}
#| message: false
#| echo: false
pip install pandas scipy statsmodels pyyaml nbformat nbclient matplotlib numpy -q
```

```{python}
#Import libarary and data file
import pandas as pd
from scipy.stats import ttest_ind
import statsmodels.api as sm
import matplotlib.pyplot as plt
import numpy as np

data = pd.read_stata("C:/Users/kcrah/Desktop/Quarto_stuff/files/karlan_list_2007.dta")
```

```{python}
data.head()
```

```{python}
data.describe()
```

:::: {.callout-note collapse="true"}
### Variable Definitions

| Variable             | Description                                                         |
|----------------------|---------------------------------------------------------------------|
| `treatment`          | Treatment                                                           |
| `control`            | Control                                                             |
| `ratio`              | Match ratio                                                         |
| `ratio2`             | 2:1 match ratio                                                     |
| `ratio3`             | 3:1 match ratio                                                     |
| `size`               | Match threshold                                                     |
| `size25`             | \$25,000 match threshold                                            |
| `size50`             | \$50,000 match threshold                                            |
| `size100`            | \$100,000 match threshold                                           |
| `sizeno`             | Unstated match threshold                                            |
| `ask`                | Suggested donation amount                                           |
| `askd1`              | Suggested donation was highest previous contribution                |
| `askd2`              | Suggested donation was 1.25 x highest previous contribution         |
| `askd3`              | Suggested donation was 1.50 x highest previous contribution         |
| `ask1`               | Highest previous contribution (for suggestion)                      |
| `ask2`               | 1.25 x highest previous contribution (for suggestion)               |
| `ask3`               | 1.50 x highest previous contribution (for suggestion)               |
| `amount`             | Dollars given                                                       |
| `gave`               | Gave anything                                                       |
| `amountchange`       | Change in amount given                                              |
| `hpa`                | Highest previous contribution                                       |
| `ltmedmra`           | Small prior donor: last gift was less than median \$35              |
| `freq`               | Number of prior donations                                           |
| `years`              | Number of years since initial donation                              |
| `year5`              | At least 5 years since initial donation                             |
| `mrm2`               | Number of months since last donation                                |
| `dormant`            | Already donated in 2005                                             |
| `female`             | Female                                                              |
| `couple`             | Couple                                                              |
| `state50one`         | State tag: 1 for one observation of each of 50 states; 0 otherwise  |
| `nonlit`             | Nonlitigation                                                       |
| `cases`              | Court cases from state in 2004-5 in which organization was involved |
| `statecnt`           | Percent of sample from state                                        |
| `stateresponse`      | Proportion of sample from the state who gave                        |
| `stateresponset`     | Proportion of treated sample from the state who gave                |
| `stateresponsec`     | Proportion of control sample from the state who gave                |
| `stateresponsetminc` | stateresponset - stateresponsec                                     |
| `perbush`            | State vote share for Bush                                           |
| `close25`            | State vote share for Bush between 47.5% and 52.5%                   |
| `red0`               | Red state                                                           |
| `blue0`              | Blue state                                                          |
| `redcty`             | Red county                                                          |
| `bluecty`            | Blue county                                                         |
| `pwhite`             | Proportion white within zip code                                    |
| `pblack`             | Proportion black within zip code                                    |
| `page18_39`          | Proportion age 18-39 within zip code                                |
| `ave_hh_sz`          | Average household size within zip code                              |
| `median_hhincome`    | Median household income within zip code                             |
| `powner`             | Proportion house owner within zip code                              |
| `psch_atlstba`       | Proportion who finished college within zip code                     |
| `pop_propurban`      | Proportion of population urban within zip code                      |

::::

:::: {.callout-note collapse="true"}
### Balance Test 
_todo: test a few variables other than the key outcome variables (for example, test months since last donation) to see if the treatment and control groups are statistically significantly different at the 95% confidence level. Do each as a t-test and separately as a linear regression, and confirm you get the exact same results from both methods. When doing a t-test, use the formula in the class slides. When doing the linear regression, regress for example mrm2 on treatment and look at the estimated coefficient on the treatment variable. It might be helpful to compare parts of your analysis to Table 1 in the paper. Be sure to comment on your results (hint: why is Table 1 included in the paper)._
::::

As an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.

First I did a t-test to compare the mrm2 between the treatment and control groups to determine if there are any statistically significant differences at the 95% confidence level.

```{python}
#Getting data for t-test and linear regression
treatment_mrm2 = data[data['treatment'] == 1]['mrm2']
control_mrm2 = data[data['treatment'] == 0]['mrm2']
```

```{python}
#T-test
t_test_result = ttest_ind(treatment_mrm2.dropna(), control_mrm2.dropna(), equal_var=False)
t_test_result
```

Then I did a linear regression to again compare the mrm2 between the treatment and control groups to determine if there are any statistically significant differences at the 95% confidence level.

```{python}
#Data for linear regression
X = sm.add_constant(data['treatment'])  # Adding a constant for the intercept
y = data['mrm2'].dropna()
X = X[X.index.isin(y.index)]  #Match index in X and y after dropping 'NA' in y
```

```{python}
#Linear regression
model = sm.OLS(y, X)
results = model.fit()
```

```{python}
t_test_result, results.summary()
```

#### T-Test Results:
- Statistic: 0.120
- P-value: 0.905

The t-test results indicate that there is no statistically significant difference in the months since the last donation between the treatment and control groups (p-value > 0.05).

#### Linear Regression Results:
- Coefficient for treatment: 0.0137
- Standard error: 0.115
- P-value: 0.905

The linear regression, shows a statistically insignificant coefficient for the treatment variable when p-value > 0.05. No impact of the treatment on the months since last donation.


## Experimental Results

:::: {.callout-note collapse="true"}
### Charitable Contribution Made
_todo: make a barplot with two bars. Each bar is the proportion of people who donated. One bar for treatment and one bar for control._

_todo: run a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made. Also run a bivariate linear regression that demonstrates the same finding. (It may help to confirm your calculations match Table 2a Panel A.) Report your statistical results and interpret them in the context of the experiment (e.g., if you found a difference with a small p-value or that was statistically significant at some threshold, what have you learned about human behavior? Use mostly English words, not numbers or stats, to explain your finding.)_

_todo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control. Confirm that your results replicate Table 3 column 1 in the paper._
::::

First, I analyze whether matched donations lead to an increased response rate of making a donation. 

I started by making a bar plot. Each bar is the proportion of people who donated. One bar for treatment and one bar for control.

```{python}
import matplotlib.pyplot as plt

#Calculate the proportion of donors in treatment and control groups
donor_proportion_treatment = data[data['treatment'] == 1]['gave'].mean()
donor_proportion_control = data[data['treatment'] == 0]['gave'].mean()

#Lable and prop
labels = ['Treatment', 'Control']
proportions = [donor_proportion_treatment, donor_proportion_control]

#Bar plot
plt.figure(figsize=(8, 5))
bars = plt.bar(labels, proportions, color=['blue', 'green'])

#Adding percentage labels above the bars
for bar in bars:
    yval = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, yval, f'{yval:.2%}', ha='center', va='bottom', fontsize=12)

plt.ylabel('Proportion Who Donated')
plt.title('Proportion of People Who Donated by Group')
plt.show()
```


The bar graph above shows that in the treatment group 2.20% of the participants made a donation. In the control group 1.79% of the participants donated.

Next I ran a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made. 

```{python}
#Match data for t-test on the binary outcome 'gave'
gave_treatment = data[data['treatment'] == 1]['gave']
gave_control = data[data['treatment'] == 0]['gave']
```

```{python}
#T-test
t_test_gave_result = ttest_ind(gave_treatment.dropna(), gave_control.dropna(), equal_var=False)
t_test_gave_result
```

#### t-test: 3.209
#### p-val: 0.0013

This shows a statistically significant difference between the treatment and control groups as shown by the p-value being below 0.05 meaning we reject the null hypothesis.

I also ran a bivariate linear regression that demonstrates the same finding. 

```{python}
#Matching data for linear regression
X_gave = sm.add_constant(data['treatment'])  #Adding a constant for the intercept
y_gave = data['gave'].dropna()
X_gave = X_gave[X_gave.index.isin(y_gave.index)]  #Match index in X and y after dropping 'NA' in y
```

```{python}
# Linear regression
model_gave = sm.OLS(y_gave, X_gave)
results_gave = model_gave.fit()
```

```{python}
t_test_gave_result, results_gave.summary()
```

#### Coefficient for treatment: 0.0042
#### P-value: 0.002

The bivariate linear regression, by regressing the binary outcome 'gave', on the treatment variable shows a positive coefficient for treatment of 0.0042. This means it's statistically significant, which matchs the aforementioned t-test.

#### Human Behavior
This shows the treatment group had a higher proportion people who donated than the control group, by 0.42%, as shown by the treatment regression coefficient.This means that the treatment of a matching grant letter is enough to persuage some into donating. 

:::: {.callout-note collapse="true"}
### Differences between Match Rates
_todo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the "figures suggest" comment the authors make on page 8?_

_todo: Assess the same issue using a regression. Specifically, create the variable `ratio1` then regress `gave` on `ratio1`, `ratio2`, and `ratio3` (or alternatively, regress `gave` on the categorical variable `ratio`). Interpret the coefficients and their statistical precision._

_todo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios.  Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?_
::::

Next, I assess the effectiveness of different sizes of matched donations on the response rate.

I started by using a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate?

```{python}
# Get data for the 2:1 match rate group 
ratio2_sample = data[data['ratio2'] == 1]
ratio2_sample
```

```{python}
# Get  data for the 1:1 match rate group 
ratio1_sample = data[data['ratio'] == 1]
ratio1_sample
```

```{python}
# Match data for t-tests comparing different match ratios
gave_ratio1 = data[data['ratio'] == '1']['gave']
gave_ratio2 = data[data['ratio2'] == 1]['gave']
```

```{python}
# Calc t-test for ratios
t_test_ratio1_vs_ratio2 = ttest_ind(gave_ratio1.dropna(), gave_ratio2.dropna(), equal_var=False)

t_test_ratio1_vs_ratio2
```

#not getting pvals ------------------------------

:::: {.callout-note collapse="true"}
### Size of Charitable Contribution
_todo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?_

_todo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients -- what did we learn? Does the treatment coefficient have a causal interpretation?_ 

_todo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot._
::::

In this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution...

I started by doing a t-test on the donation amount based on treatment status, to see if there's a statistically significant difference in the amount donated between the treatment group and the control group.

```{python}
#Get donation amounts for treatment and control groups
treatment_amounts = data[data['treatment'] == 1]['amount']
control_amounts = data[data['treatment'] == 0]['amount']

#t-test between the two groups
t_test_results = ttest_ind(treatment_amounts.dropna(), control_amounts.dropna(), equal_var=False)

t_test_results
```
#### t-test: 1.92
#### p-val: 0.06

The t-test shows that the treatment mean donation the control group, with the difference being 1.918. The p-val of 0.06 which is higher than 0.05 means there is a small difference in the means of the donation amounts between the treatment and control groups. 

## Simulation Experiment

As a reminder of how the t-statistic "works," in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.

Suppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made. 

Further suppose that the true distribution of respondents who do get a charitable donation match of any size  is Bernoulli with probability p=0.022 that a donation is made.

:::: {.callout-note collapse="true"}
### Law of Large Numbers
_to do:  Make a plot like those on slide 43 from our first class and explain the plot to the reader. To do this, you will simulate 100,000 draws from the control distribution and 10,000 draws from the treatment distribution. You'll then calculate a vector of 10,000 differences, and then you'll plot the cumulative average of that vector of differences. Comment on whether the cumulative average approaches the true difference in means._
::::

First I made a plot like those on slide 43 from our first class. The plot shows... 


This was done by simulating 100,000 draws from the control distribution and 10,000 draws from the treatment distribution. I then calculated a vector of 10,000 differences, and then I ploted the cumulative average of the vector of differences. The cumulative average approaches the true difference in means because...

```{python}



```

:::: {.callout-note collapse="true"}
### Central Limit Theorem
_to do: Make 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 and explain these plots to the reader. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. Comment on whether zero is in the "middle" of the distribution or whether it's in the "tail."_
::::

I made 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 which show...
I did this for sample size 50,200,500 and 1000 by taking the respective sample draws from each of the control and treatment distributions, and calculating the average difference between those draws. Then repeating that process 999 more times so I had 1000 averages. The zero is the "middle" of the distribution for all 4 histograms. 

```{python}
#Calculate means and standard deviations for 'gave' 
treatment_gave = data[data['treatment'] == 1]['gave']
control_gave = data[data['treatment'] == 0]['gave']

mean_treatment = treatment_gave.mean()
mean_control = control_gave.mean()
std_treatment = treatment_gave.std()
std_control = control_gave.std()

#Show mean and std dev for treat and control
print("Treatment Mean:", mean_treatment, "Control Mean:", mean_control)

print("Treatment Std Dev:", std_treatment, "Control Std Dev:", std_control)
```

```{python}
#Function to simulate differences
def simulate_differences(sample_size, num_simulations):
    differences = []
    for _ in range(num_simulations):
        treatment_sample = np.random.binomial(1, mean_treatment, sample_size)
        control_sample = np.random.binomial(1, mean_control, sample_size)
        differences.append(treatment_sample.mean() - control_sample.mean())
    return differences

#Get sample size and 1000 simulation
sample_sizes = [50, 200, 500, 1000]
num_simulations = 1000

#Make 4 histograms
for size in sample_sizes:
    diffs = simulate_differences(size, num_simulations)
    plt.figure()
    plt.hist(diffs, bins=30, alpha=0.75, color='blue')
    plt.axvline(x=0, color='red', linestyle='--', label='Zero')
    plt.title(f'Histogram of Differences for Sample Size {size}')
    plt.xlabel('Difference in Proportions')
    plt.ylabel('Frequency')
    plt.legend()
    plt.show()
```

#### Histogram Explanation:
All 4 histrograms show the zero line is at 0.0. This means that there is no statistically significant effect of the treatment on the measured outcome across the sampled observations.