[
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Rahul’s Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Rahul’s Website",
    "section": "",
    "text": "Welcome to my website :3"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Projects",
    "section": "",
    "text": "Homework 1\n\n\n\n\n\n\nRahul\n\n\nApr 16, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/project1/index.html",
    "href": "projects/project1/index.html",
    "title": "Homework 1",
    "section": "",
    "text": "Warning: package 'tidyverse' was built under R version 4.3.3\n\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\n\nWarning: package 'tibble' was built under R version 4.3.3\n\n\nWarning: package 'tidyr' was built under R version 4.3.3\n\n\nWarning: package 'readr' was built under R version 4.3.3\n\n\nWarning: package 'purrr' was built under R version 4.3.3\n\n\nWarning: package 'dplyr' was built under R version 4.3.3\n\n\nWarning: package 'stringr' was built under R version 4.3.3\n\n\nWarning: package 'forcats' was built under R version 4.3.3\n\n\nWarning: package 'lubridate' was built under R version 4.3.3"
  },
  {
    "objectID": "projects/project1/index.html#sub-header",
    "href": "projects/project1/index.html#sub-header",
    "title": "My Main Project",
    "section": "",
    "text": "Data2"
  },
  {
    "objectID": "projects/project1/index.html#sub-section",
    "href": "projects/project1/index.html#sub-section",
    "title": "Homework 1",
    "section": "Sub-section",
    "text": "Sub-section\n\nHeader\n\nsome\nwords\nin\nbullets\n\n\nsome\nnumbers\nin\na\nlist\n\ntext can be bold, or italics, or strikethrough\nMy website is https://kcrahul1999.github.io/ or here"
  },
  {
    "objectID": "projects/project1/index.html#tab1",
    "href": "projects/project1/index.html#tab1",
    "title": "Homework 1",
    "section": "tab1",
    "text": "tab1"
  },
  {
    "objectID": "projects/project1/index.html#tab2",
    "href": "projects/project1/index.html#tab2",
    "title": "Homework 1",
    "section": "tab2",
    "text": "tab2"
  },
  {
    "objectID": "hw1_questions.html",
    "href": "hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "hw1_questions.html#introduction",
    "href": "hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "hw1_questions.html#data",
    "href": "hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\ntodo: Read the data into R/Python and describe the data\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\ntodo: test a few variables other than the key outcome variables (for example, test months since last donation) to see if the treatment and control groups are statistically significantly different at the 95% confidence level. Do each as a t-test and separately as a linear regression, and confirm you get the exact same results from both methods. When doing a t-test, use the formula in the class slides. When doing the linear regression, regress for example mrm2 on treatment and look at the estimated coefficient on the treatment variable. It might be helpful to compare parts of your analysis to Table 1 in the paper. Be sure to comment on your results (hint: why is Table 1 included in the paper)."
  },
  {
    "objectID": "hw1_questions.html#experimental-results",
    "href": "hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\ntodo: make a barplot with two bars. Each bar is the proportion of people who donated. One bar for treatment and one bar for control.\ntodo: run a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made. Also run a bivariate linear regression that demonstrates the same finding. (It may help to confirm your calculations match Table 2a Panel A.) Report your statistical results and interpret them in the context of the experiment (e.g., if you found a difference with a small p-value or that was statistically significant at some threshold, what have you learned about human behavior? Use mostly English words, not numbers or stats, to explain your finding.)\ntodo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control. Confirm that your results replicate Table 3 column 1 in the paper.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\ntodo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the “figures suggest” comment the authors make on page 8?\ntodo: Assess the same issue using a regression. Specifically, create the variable ratio1 then regress gave on ratio1, ratio2, and ratio3 (or alternatively, regress gave on the categorical variable ratio). Interpret the coefficients and their statistical precision.\ntodo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\ntodo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?\ntodo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients – what did we learn? Does the treatment coefficient have a causal interpretation?\ntodo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot."
  },
  {
    "objectID": "hw1_questions.html#simulation-experiment",
    "href": "hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nto do: Make a plot like those on slide 43 from our first class and explain the plot to the reader. To do this, you will simulate 100,00 draws from the control distribution and 10,000 draws from the treatment distribution. You’ll then calculate a vector of 10,000 differences, and then you’ll plot the cumulative average of that vector of differences. Comment on whether the cumulative average approaches the true difference in means.\n\n\nCentral Limit Theorem\nto do: Make 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 and explain these plots to the reader. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. Comment on whether zero is in the “middle” of the distribution or whether it’s in the “tail.”"
  },
  {
    "objectID": "homeworks/homework 1/hw1_questions.html",
    "href": "homeworks/homework 1/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "homeworks/homework 1/hw1_questions.html#introduction",
    "href": "homeworks/homework 1/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "homeworks/homework 1/hw1_questions.html#data",
    "href": "homeworks/homework 1/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\ntodo: Read the data into R/Python and describe the data\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\ntodo: test a few variables other than the key outcome variables (for example, test months since last donation) to see if the treatment and control groups are statistically significantly different at the 95% confidence level. Do each as a t-test and separately as a linear regression, and confirm you get the exact same results from both methods. When doing a t-test, use the formula in the class slides. When doing the linear regression, regress for example mrm2 on treatment and look at the estimated coefficient on the treatment variable. It might be helpful to compare parts of your analysis to Table 1 in the paper. Be sure to comment on your results (hint: why is Table 1 included in the paper)."
  },
  {
    "objectID": "homeworks/homework 1/hw1_questions.html#experimental-results",
    "href": "homeworks/homework 1/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\ntodo: make a barplot with two bars. Each bar is the proportion of people who donated. One bar for treatment and one bar for control.\ntodo: run a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made. Also run a bivariate linear regression that demonstrates the same finding. (It may help to confirm your calculations match Table 2a Panel A.) Report your statistical results and interpret them in the context of the experiment (e.g., if you found a difference with a small p-value or that was statistically significant at some threshold, what have you learned about human behavior? Use mostly English words, not numbers or stats, to explain your finding.)\ntodo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control. Confirm that your results replicate Table 3 column 1 in the paper.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\ntodo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the “figures suggest” comment the authors make on page 8?\ntodo: Assess the same issue using a regression. Specifically, create the variable ratio1 then regress gave on ratio1, ratio2, and ratio3 (or alternatively, regress gave on the categorical variable ratio). Interpret the coefficients and their statistical precision.\ntodo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\ntodo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?\ntodo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients – what did we learn? Does the treatment coefficient have a causal interpretation?\ntodo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot."
  },
  {
    "objectID": "homeworks/homework 1/hw1_questions.html#simulation-experiment",
    "href": "homeworks/homework 1/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nto do: Make a plot like those on slide 43 from our first class and explain the plot to the reader. To do this, you will simulate 100,00 draws from the control distribution and 10,000 draws from the treatment distribution. You’ll then calculate a vector of 10,000 differences, and then you’ll plot the cumulative average of that vector of differences. Comment on whether the cumulative average approaches the true difference in means.\n\n\nCentral Limit Theorem\nto do: Make 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 and explain these plots to the reader. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. Comment on whether zero is in the “middle” of the distribution or whether it’s in the “tail.”"
  },
  {
    "objectID": "homeworks/homework 1/index.html",
    "href": "homeworks/homework 1/index.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nIn an effort to under stand “the economics of charity” Karlan and List found that a matching grant letter significantly boosts both revenue per solicitation and the likelihood of donationb by 19$ and 22$ respectively. The experiment itself, started by randomly assigning to either a control group or a matching grant treatment group, and within the matching grant treatment group individuals were randomly assigned to different matching grant rates, matching grant maximum amounts, and suggested donation amounts.\nIntrestingly larger matching ratios of $3:$1 and $2:$1 do not yield additional revenue when compared to the $1:$1 ratio. The study also considers spatial heterogeneity, finding that the influence of matching gifts varies significantly based on the political environment, with a stronger effect observed in red states that supported George W. Bush in the 2004 presidential election. This means that an individual’s political beliefs has influences the level of giving, and their responsiveness to different treatments.\nThe researchers state that this study and previosuly similar conducted studies are all of course hypothetical. Therefore they state that the study might be viewed as a useful test of scope using an approach consistent with natural provision of a real public good. However despite variations in outcomes across studies, the researchers state that all studies convey the complexity of charitable giving behavior and the need for further empirical investigation.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "homeworks/homework 1/index.html#introduction",
    "href": "homeworks/homework 1/index.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nIn an effort to under stand “the economics of charity” Karlan and List found that a matching grant letter significantly boosts both revenue per solicitation and the likelihood of donationb by 19$ and 22$ respectively. The experiment itself, started by randomly assigning to either a control group or a matching grant treatment group, and within the matching grant treatment group individuals were randomly assigned to different matching grant rates, matching grant maximum amounts, and suggested donation amounts.\nIntrestingly larger matching ratios of $3:$1 and $2:$1 do not yield additional revenue when compared to the $1:$1 ratio. The study also considers spatial heterogeneity, finding that the influence of matching gifts varies significantly based on the political environment, with a stronger effect observed in red states that supported George W. Bush in the 2004 presidential election. This means that an individual’s political beliefs has influences the level of giving, and their responsiveness to different treatments.\nThe researchers state that this study and previosuly similar conducted studies are all of course hypothetical. Therefore they state that the study might be viewed as a useful test of scope using an approach consistent with natural provision of a real public good. However despite variations in outcomes across studies, the researchers state that all studies convey the complexity of charitable giving behavior and the need for further empirical investigation.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "homeworks/homework 1/index.html#data",
    "href": "homeworks/homework 1/index.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\n\n\nNote: you may need to restart the kernel to use updated packages.\n\n\n\n[notice] A new release of pip is available: 23.2.1 -&gt; 24.0\n[notice] To update, run: C:\\Users\\kcrah\\AppData\\Local\\Programs\\Python\\Python312\\pythonw.exe -m pip install --upgrade pip\n\n\n\n#Import libarary and data file\nimport pandas as pd\nfrom scipy.stats import ttest_ind\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndata = pd.read_stata(\"C:/Users/kcrah/Desktop/Quarto_stuff/files/karlan_list_2007.dta\")\n\n\ndata.head()\n\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.0\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.0\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.0\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.0\n\n\n\n\n5 rows × 51 columns\n\n\n\n\n\ndata.describe()\n\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio2\nratio3\nsize25\nsize50\nsize100\nsizeno\naskd1\naskd2\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\ncount\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n...\n49978.000000\n49978.000000\n48217.000000\n48047.000000\n48217.000000\n48221.000000\n48209.000000\n48214.000000\n48215.000000\n48217.000000\n\n\nmean\n0.666813\n0.333187\n0.222311\n0.222211\n0.166723\n0.166623\n0.166723\n0.166743\n0.222311\n0.222291\n...\n0.510245\n0.488715\n0.819599\n0.086710\n0.321694\n2.429012\n54815.700533\n0.669418\n0.391661\n0.871968\n\n\nstd\n0.471357\n0.471357\n0.415803\n0.415736\n0.372732\n0.372643\n0.372732\n0.372750\n0.415803\n0.415790\n...\n0.499900\n0.499878\n0.168561\n0.135868\n0.103039\n0.378115\n22027.316665\n0.193405\n0.186599\n0.258654\n\n\nmin\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.009418\n0.000000\n0.000000\n0.000000\n5000.000000\n0.000000\n0.000000\n0.000000\n\n\n25%\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.755845\n0.014729\n0.258311\n2.210000\n39181.000000\n0.560222\n0.235647\n0.884929\n\n\n50%\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n0.000000\n0.872797\n0.036554\n0.305534\n2.440000\n50673.000000\n0.712296\n0.373744\n1.000000\n\n\n75%\n1.000000\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n1.000000\n0.938827\n0.090882\n0.369132\n2.660000\n66005.000000\n0.816798\n0.530036\n1.000000\n\n\nmax\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n...\n1.000000\n1.000000\n1.000000\n0.989622\n0.997544\n5.270000\n200001.000000\n1.000000\n1.000000\n1.000000\n\n\n\n\n8 rows × 48 columns\n\n\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\n\n\n\n\nBalance Test\n\n\n\n\n\ntodo: test a few variables other than the key outcome variables (for example, test months since last donation) to see if the treatment and control groups are statistically significantly different at the 95% confidence level. Do each as a t-test and separately as a linear regression, and confirm you get the exact same results from both methods. When doing a t-test, use the formula in the class slides. When doing the linear regression, regress for example mrm2 on treatment and look at the estimated coefficient on the treatment variable. It might be helpful to compare parts of your analysis to Table 1 in the paper. Be sure to comment on your results (hint: why is Table 1 included in the paper).\n\n\n\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\nFirst I did a t-test to compare the mrm2 between the treatment and control groups to determine if there are any statistically significant differences at the 95% confidence level.\n\n#Getting data for t-test and linear regression\ntreatment_mrm2 = data[data['treatment'] == 1]['mrm2']\ncontrol_mrm2 = data[data['treatment'] == 0]['mrm2']\n\n\n#T-test\nt_test_result = ttest_ind(treatment_mrm2.dropna(), control_mrm2.dropna(), equal_var=False)\nt_test_result\n\nTtestResult(statistic=0.11953155228177251, pvalue=0.9048549631450832, df=33394.47581389535)\n\n\nThen I did a linear regression to again compare the mrm2 between the treatment and control groups to determine if there are any statistically significant differences at the 95% confidence level.\n\n#Data for linear regression\nX = sm.add_constant(data['treatment'])  # Adding a constant for the intercept\ny = data['mrm2'].dropna()\nX = X[X.index.isin(y.index)]  #Match index in X and y after dropping 'NA' in y\n\n\n#Linear regression\nmodel = sm.OLS(y, X)\nresults = model.fit()\n\n\nt_test_result, results.summary()\n\n(TtestResult(statistic=0.11953155228177251, pvalue=0.9048549631450832, df=33394.47581389535),\n &lt;class 'statsmodels.iolib.summary.Summary'&gt;\n \"\"\"\n                             OLS Regression Results                            \n ==============================================================================\n Dep. Variable:                   mrm2   R-squared:                       0.000\n Model:                            OLS   Adj. R-squared:                 -0.000\n Method:                 Least Squares   F-statistic:                   0.01428\n Date:                Tue, 16 Apr 2024   Prob (F-statistic):              0.905\n Time:                        17:56:49   Log-Likelihood:            -1.9585e+05\n No. Observations:               50082   AIC:                         3.917e+05\n Df Residuals:                   50080   BIC:                         3.917e+05\n Df Model:                           1                                         \n Covariance Type:            nonrobust                                         \n ==============================================================================\n                  coef    std err          t      P&gt;|t|      [0.025      0.975]\n ------------------------------------------------------------------------------\n const         12.9981      0.094    138.979      0.000      12.815      13.181\n treatment      0.0137      0.115      0.119      0.905      -0.211       0.238\n ==============================================================================\n Omnibus:                     8031.352   Durbin-Watson:                   2.004\n Prob(Omnibus):                  0.000   Jarque-Bera (JB):            12471.135\n Skew:                           1.163   Prob(JB):                         0.00\n Kurtosis:                       3.751   Cond. No.                         3.23\n ==============================================================================\n \n Notes:\n [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n \"\"\")\n\n\n\nT-Test Results:\n\nStatistic: 0.120\nP-value: 0.905\n\nThe t-test results indicate that there is no statistically significant difference in the months since the last donation between the treatment and control groups (p-value &gt; 0.05).\n\n\nLinear Regression Results:\n\nCoefficient for treatment: 0.0137\nStandard error: 0.115\nP-value: 0.905\n\nThe linear regression, shows a statistically insignificant coefficient for the treatment variable when p-value &gt; 0.05. No impact of the treatment on the months since last donation."
  },
  {
    "objectID": "homeworks/homework 1/index.html#experimental-results",
    "href": "homeworks/homework 1/index.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\n\n\n\n\n\nCharitable Contribution Made\n\n\n\n\n\ntodo: make a barplot with two bars. Each bar is the proportion of people who donated. One bar for treatment and one bar for control.\ntodo: run a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made. Also run a bivariate linear regression that demonstrates the same finding. (It may help to confirm your calculations match Table 2a Panel A.) Report your statistical results and interpret them in the context of the experiment (e.g., if you found a difference with a small p-value or that was statistically significant at some threshold, what have you learned about human behavior? Use mostly English words, not numbers or stats, to explain your finding.)\ntodo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control. Confirm that your results replicate Table 3 column 1 in the paper.\n\n\n\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\nI started by making a bar plot. Each bar is the proportion of people who donated. One bar for treatment and one bar for control.\n\nimport matplotlib.pyplot as plt\n\n#Calculate the proportion of donors in treatment and control groups\ndonor_proportion_treatment = data[data['treatment'] == 1]['gave'].mean()\ndonor_proportion_control = data[data['treatment'] == 0]['gave'].mean()\n\n#Lable and prop\nlabels = ['Treatment', 'Control']\nproportions = [donor_proportion_treatment, donor_proportion_control]\n\n#Bar plot\nplt.figure(figsize=(8, 5))\nbars = plt.bar(labels, proportions, color=['blue', 'green'])\n\n#Adding percentage labels above the bars\nfor bar in bars:\n    yval = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2, yval, f'{yval:.2%}', ha='center', va='bottom', fontsize=12)\n\nplt.ylabel('Proportion Who Donated')\nplt.title('Proportion of People Who Donated by Group')\nplt.show()\n\n\n\n\n\n\n\n\nThe bar graph above shows that in the treatment group 2.20% of the participants made a donation. In the control group 1.79% of the participants donated.\nNext I ran a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made.\n\n#Match data for t-test on the binary outcome 'gave'\ngave_treatment = data[data['treatment'] == 1]['gave']\ngave_control = data[data['treatment'] == 0]['gave']\n\n\n#T-test\nt_test_gave_result = ttest_ind(gave_treatment.dropna(), gave_control.dropna(), equal_var=False)\nt_test_gave_result\n\nTtestResult(statistic=3.2094621908279835, pvalue=0.001330982345091417, df=36576.84238986656)\n\n\n\nt-test: 3.209\n\n\np-val: 0.0013\nThis shows a statistically significant difference between the treatment and control groups as shown by the p-value being below 0.05 meaning we reject the null hypothesis.\nI also ran a bivariate linear regression that demonstrates the same finding.\n\n#Matching data for linear regression\nX_gave = sm.add_constant(data['treatment'])  #Adding a constant for the intercept\ny_gave = data['gave'].dropna()\nX_gave = X_gave[X_gave.index.isin(y_gave.index)]  #Match index in X and y after dropping 'NA' in y\n\n\n# Linear regression\nmodel_gave = sm.OLS(y_gave, X_gave)\nresults_gave = model_gave.fit()\n\n\nt_test_gave_result, results_gave.summary()\n\n(TtestResult(statistic=3.2094621908279835, pvalue=0.001330982345091417, df=36576.84238986656),\n &lt;class 'statsmodels.iolib.summary.Summary'&gt;\n \"\"\"\n                             OLS Regression Results                            \n ==============================================================================\n Dep. Variable:                   gave   R-squared:                       0.000\n Model:                            OLS   Adj. R-squared:                  0.000\n Method:                 Least Squares   F-statistic:                     9.618\n Date:                Tue, 16 Apr 2024   Prob (F-statistic):            0.00193\n Time:                        17:56:50   Log-Likelihood:                 26630.\n No. Observations:               50083   AIC:                        -5.326e+04\n Df Residuals:                   50081   BIC:                        -5.324e+04\n Df Model:                           1                                         \n Covariance Type:            nonrobust                                         \n ==============================================================================\n                  coef    std err          t      P&gt;|t|      [0.025      0.975]\n ------------------------------------------------------------------------------\n const          0.0179      0.001     16.225      0.000       0.016       0.020\n treatment      0.0042      0.001      3.101      0.002       0.002       0.007\n ==============================================================================\n Omnibus:                    59814.280   Durbin-Watson:                   2.005\n Prob(Omnibus):                  0.000   Jarque-Bera (JB):          4317152.727\n Skew:                           6.740   Prob(JB):                         0.00\n Kurtosis:                      46.440   Cond. No.                         3.23\n ==============================================================================\n \n Notes:\n [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n \"\"\")\n\n\n\n\nCoefficient for treatment: 0.0042\n\n\nP-value: 0.002\nThe bivariate linear regression, by regressing the binary outcome ‘gave’, on the treatment variable shows a positive coefficient for treatment of 0.0042. This means it’s statistically significant, which matchs the aforementioned t-test.\n\n\nHuman Behavior\nThis shows the treatment group had a higher proportion people who donated than the control group, by 0.42%, as shown by the treatment regression coefficient.This means that the treatment of a matching grant letter is enough to persuage some into donating.\n\n\n\n\n\n\nDifferences between Match Rates\n\n\n\n\n\ntodo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the “figures suggest” comment the authors make on page 8?\ntodo: Assess the same issue using a regression. Specifically, create the variable ratio1 then regress gave on ratio1, ratio2, and ratio3 (or alternatively, regress gave on the categorical variable ratio). Interpret the coefficients and their statistical precision.\ntodo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?\n\n\n\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\nI started by using a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate?\n\n# Get data for the 2:1 match rate group \nratio2_sample = data[data['ratio2'] == 1]\nratio2_sample\n\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n7\n1\n0\n2\n1\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.903297\n0.019494\n0.212040\n2.47\n141527.0\n0.897906\n0.708122\n1.000000\n\n\n8\n1\n0\n2\n1\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.927851\n0.004739\n0.249465\n2.49\n37017.0\n0.763151\n0.205828\n0.599052\n\n\n11\n1\n0\n2\n1\n0\n$50,000\n0\n1\n0\n0\n...\n1.0\n0.0\n0.816659\n0.042910\n0.345686\n2.35\n50163.0\n0.468334\n0.254896\n1.000000\n\n\n13\n1\n0\n2\n1\n0\n$25,000\n1\n0\n0\n0\n...\n1.0\n0.0\n0.967608\n0.015739\n0.284836\n2.85\n67859.0\n0.883114\n0.405628\n0.970737\n\n\n19\n1\n0\n2\n1\n0\n$25,000\n1\n0\n0\n0\n...\n1.0\n0.0\n0.904871\n0.004875\n0.273782\n2.70\n41553.0\n0.726801\n0.181954\n0.922775\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n50055\n1\n0\n2\n1\n0\n$25,000\n1\n0\n0\n0\n...\n1.0\n0.0\n0.585023\n0.304967\n0.267524\n2.86\n74903.0\n0.828101\n0.478660\n1.000000\n\n\n50059\n1\n0\n2\n1\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.582680\n0.193563\n0.451955\n2.02\n34293.0\n0.325738\n0.391760\n1.000000\n\n\n50064\n1\n0\n2\n1\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.848056\n0.036633\n0.193733\n2.65\n113788.0\n0.851489\n0.774322\n1.000000\n\n\n50074\n1\n0\n2\n1\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.907267\n0.029272\n0.288404\n2.97\n66051.0\n0.884930\n0.276022\n0.979433\n\n\n50075\n1\n0\n2\n1\n0\nUnstated\n0\n0\n0\n1\n...\n0.0\n1.0\n0.526869\n0.010935\n0.287106\n2.76\n100020.0\n0.640149\n0.650302\n0.990903\n\n\n\n\n11134 rows × 51 columns\n\n\n\n\n\n# Get  data for the 1:1 match rate group \nratio1_sample = data[data['ratio'] == 1]\nratio1_sample\n\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.000000\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.000000\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.000000\n\n\n6\n1\n0\n1\n0\n0\n$25,000\n1\n0\n0\n0\n...\n1.0\n0.0\n0.882912\n0.097408\n0.376446\n2.10\n54655.0\n0.695880\n0.554568\n1.000000\n\n\n9\n1\n0\n1\n0\n0\n$25,000\n1\n0\n0\n0\n...\n0.0\n1.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n50058\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.877152\n0.061334\n0.453103\n2.60\n62258.0\n0.702048\n0.481502\n0.986119\n\n\n50060\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.807919\n0.121061\n0.353253\n2.17\n40867.0\n0.743756\n0.351826\n1.000000\n\n\n50065\n1\n0\n1\n0\n0\n$25,000\n1\n0\n0\n0\n...\n0.0\n1.0\n0.902345\n0.056393\n0.265941\n1.98\n48920.0\n0.649136\n0.400955\n1.000000\n\n\n50066\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.410729\n0.040790\n0.376367\n3.24\n30152.0\n0.250095\n0.123647\n1.000000\n\n\n50078\n1\n0\n1\n0\n0\n$25,000\n1\n0\n0\n0\n...\n0.0\n1.0\n0.872797\n0.089959\n0.257265\n2.13\n45047.0\n0.771316\n0.263744\n1.000000\n\n\n\n\n11133 rows × 51 columns\n\n\n\n\n\n# Match data for t-tests comparing different match ratios\ngave_ratio1 = data[data['ratio'] == '1']['gave']\ngave_ratio2 = data[data['ratio2'] == 1]['gave']\n\n\n# Calc t-test for ratios\nt_test_ratio1_vs_ratio2 = ttest_ind(gave_ratio1.dropna(), gave_ratio2.dropna(), equal_var=False)\n\nt_test_ratio1_vs_ratio2\n\nTtestResult(statistic=nan, pvalue=nan, df=nan)\n\n\n#not getting pvals ——————————\n\n\n\n\n\n\nSize of Charitable Contribution\n\n\n\n\n\ntodo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?\ntodo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients – what did we learn? Does the treatment coefficient have a causal interpretation?\ntodo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot.\n\n\n\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution…\nI started by doing a t-test on the donation amount based on treatment status, to see if there’s a statistically significant difference in the amount donated between the treatment group and the control group.\n\n#Get donation amounts for treatment and control groups\ntreatment_amounts = data[data['treatment'] == 1]['amount']\ncontrol_amounts = data[data['treatment'] == 0]['amount']\n\n#t-test between the two groups\nt_test_results = ttest_ind(treatment_amounts.dropna(), control_amounts.dropna(), equal_var=False)\n\nt_test_results\n\nTtestResult(statistic=1.9182618934467577, pvalue=0.055085665289183336, df=36216.05660774625)\n\n\n\n\nt-test: 1.92\n\n\np-val: 0.06\nThe t-test shows that the treatment mean donation the control group, with the difference being 1.918. The p-val of 0.06 which is higher than 0.05 means there is a small difference in the means of the donation amounts between the treatment and control groups."
  },
  {
    "objectID": "homeworks/homework 1/index.html#simulation-experiment",
    "href": "homeworks/homework 1/index.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\n\n\n\n\n\nLaw of Large Numbers\n\n\n\n\n\nto do: Make a plot like those on slide 43 from our first class and explain the plot to the reader. To do this, you will simulate 100,000 draws from the control distribution and 10,000 draws from the treatment distribution. You’ll then calculate a vector of 10,000 differences, and then you’ll plot the cumulative average of that vector of differences. Comment on whether the cumulative average approaches the true difference in means.\n\n\n\nFirst I made a plot like those on slide 43 from our first class. The plot shows…\nThis was done by simulating 100,000 draws from the control distribution and 10,000 draws from the treatment distribution. I then calculated a vector of 10,000 differences, and then I ploted the cumulative average of the vector of differences. The cumulative average approaches the true difference in means because…\n\n\n\n\n\n\nCentral Limit Theorem\n\n\n\n\n\nto do: Make 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 and explain these plots to the reader. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. Comment on whether zero is in the “middle” of the distribution or whether it’s in the “tail.”\n\n\n\nI made 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 which show… I did this for sample size 50,200,500 and 1000 by taking the respective sample draws from each of the control and treatment distributions, and calculating the average difference between those draws. Then repeating that process 999 more times so I had 1000 averages. The zero is the “middle” of the distribution for all 4 histograms.\n\n#Calculate means and standard deviations for 'gave' \ntreatment_gave = data[data['treatment'] == 1]['gave']\ncontrol_gave = data[data['treatment'] == 0]['gave']\n\nmean_treatment = treatment_gave.mean()\nmean_control = control_gave.mean()\nstd_treatment = treatment_gave.std()\nstd_control = control_gave.std()\n\n#Show mean and std dev for treat and control\nprint(\"Treatment Mean:\", mean_treatment, \"Control Mean:\", mean_control)\n\nprint(\"Treatment Std Dev:\", std_treatment, \"Control Std Dev:\", std_control)\n\nTreatment Mean: 0.02203856749311295 Control Mean: 0.017858212980164198\nTreatment Std Dev: 0.14681115226051514 Control Std Dev: 0.13243998017151457\n\n\n\n#Function to simulate differences\ndef simulate_differences(sample_size, num_simulations):\n    differences = []\n    for _ in range(num_simulations):\n        treatment_sample = np.random.binomial(1, mean_treatment, sample_size)\n        control_sample = np.random.binomial(1, mean_control, sample_size)\n        differences.append(treatment_sample.mean() - control_sample.mean())\n    return differences\n\n#Get sample size and 1000 simulation\nsample_sizes = [50, 200, 500, 1000]\nnum_simulations = 1000\n\n#Make 4 histograms\nfor size in sample_sizes:\n    diffs = simulate_differences(size, num_simulations)\n    plt.figure()\n    plt.hist(diffs, bins=30, alpha=0.75, color='blue')\n    plt.axvline(x=0, color='red', linestyle='--', label='Zero')\n    plt.title(f'Histogram of Differences for Sample Size {size}')\n    plt.xlabel('Difference in Proportions')\n    plt.ylabel('Frequency')\n    plt.legend()\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHistogram Explanation:\nAll 4 histrograms show the zero line is at 0.0. This means that there is no statistically significant effect of the treatment on the measured outcome across the sampled observations."
  },
  {
    "objectID": "homeworks.html",
    "href": "homeworks.html",
    "title": "My Homeworks",
    "section": "",
    "text": "A Replication of Karlan and List (2007)\n\n\n\n\n\n\nRahul Kc\n\n\nMay 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nPoisson Regression Examples\n\n\n\n\n\n\nRahul Kc\n\n\nMay 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nMultinomial Logit Examples\n\n\n\n\n\n\nRahul Kc\n\n\nMay 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nKey Drivers Analysis\n\n\n\n\n\n\nRahul Kc\n\n\nMay 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nKey Drivers Analysis\n\n\n\n\n\n\nRahul Kc\n\n\nMay 30, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "homeworks/homework 2/index.html",
    "href": "homeworks/homework 2/index.html",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\n\n\n\nData\n\n\n\n\n\ntodo: Read in data.\ntodo: Compare histograms and means of number of patents by customer status. What do you observe?\n\n\n\n\n\nNote: you may need to restart the kernel to use updated packages.\n\n\n\n[notice] A new release of pip is available: 23.2.1 -&gt; 24.0\n[notice] To update, run: C:\\Users\\kcrah\\AppData\\Local\\Programs\\Python\\Python312\\pythonw.exe -m pip install --upgrade pip\n\n\n\n#Import libarary and data file\nimport pandas as pd\nfrom scipy.stats import ttest_ind\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport math  \nimport scipy.optimize as optimize\nimport scipy.stats as stats\nimport pandas as pd\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\nair = pd.read_csv(\"C:/Users/kcrah/Desktop/Quarto_stuff/files/airbnb.csv\")\nblue = pd.read_csv(\"C:/Users/kcrah/Desktop/Quarto_stuff/files/blueprinty.csv\")\n\n\nblue.head()\n\n\n\n\n\n\n\n\n\nUnnamed: 0\npatents\nregion\nage\niscustomer\n\n\n\n\n0\n1\n0\nMidwest\n32.5\n0\n\n\n1\n786\n3\nSouthwest\n37.5\n0\n\n\n2\n348\n4\nNorthwest\n27.0\n1\n\n\n3\n927\n3\nNortheast\n24.5\n0\n\n\n4\n830\n3\nSouthwest\n37.0\n0\n\n\n\n\n\n\n\n\n\nblue.describe()\n\n\n\n\n\n\n\n\n\nUnnamed: 0\npatents\nage\niscustomer\n\n\n\n\ncount\n1500.000000\n1500.000000\n1500.000000\n1500.000000\n\n\nmean\n750.500000\n3.684667\n26.357667\n0.131333\n\n\nstd\n433.157015\n2.352500\n7.242528\n0.337877\n\n\nmin\n1.000000\n0.000000\n9.000000\n0.000000\n\n\n25%\n375.750000\n2.000000\n21.000000\n0.000000\n\n\n50%\n750.500000\n3.000000\n26.000000\n0.000000\n\n\n75%\n1125.250000\n5.000000\n31.625000\n0.000000\n\n\nmax\n1500.000000\n16.000000\n49.000000\n1.000000\n\n\n\n\n\n\n\n\nFirst I compare histograms and means of number of patents by customer status. I observe that the mean of non customers (iscustomer=0) is 3.62 and the mean of customers (iscustomer=1) is 4.09.\nThis means firms using the software have a higher average number of patents to firms that don’t.\n\n#Calculate the mean number of patents for customers and non-customers\nmeans = blue.groupby('iscustomer')['patents'].mean()\n\n#Create histograms to compare the distribution of patents\nplt.figure(figsize=(10, 6))\nblue[blue['iscustomer'] == 1]['patents'].hist(alpha=0.5, label='Customers', bins=20)\nblue[blue['iscustomer'] == 0]['patents'].hist(alpha=0.5, label='Non-Customers', bins=20)\nplt.title('Histogram of Number of Patents by Customer Status')\nplt.xlabel('Number of Patents')\nplt.ylabel('Frequency')\nplt.legend()\nplt.show()\n\nprint(means)\n\n\n\n\n\n\n\n\niscustomer\n0    3.623177\n1    4.091371\nName: patents, dtype: float64\n\n\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\nTherefore I compared regions and ages by customer status.\n\n\n\n\n\n\nTODO\n\n\n\n\n\ntodo: Compare regions and ages by customer status. What do you observe?\n\n\n\nWe see below that the number of non-customers is far greater than the number of customers for all regions. The ‘1’ representing customers and ‘0’ representing non-customers.\n\n#Accounting missing data for cols 'region' and 'age'\nblue['region'] = blue['region'].fillna('Unknown')\nblue['age'] = blue['age'].fillna(blue['age'].mean())\n\n#Compare regions by customer status\nregion_summary = blue.groupby(['region', 'iscustomer']).size().unstack(fill_value=0)\n\n#Plott regional distribution by customer status\nregion_summary.plot(kind='bar', figsize=(14, 7), stacked=True)\nplt.title('Distribution of Firms by Region and Customer Status')\nplt.xlabel('Region')\nplt.ylabel('Number of Firms')\nplt.legend(title='Customer Status', labels=['Non-Customers', 'Customers'])\nplt.xticks(rotation=45)\nplt.show()\n\n#Group by 'region' and 'iscustomer' and get count of firms\nregion_customer_counts = blue.groupby(['region', 'iscustomer']).size().unstack(fill_value=0)\n\nprint(region_customer_counts)\n\n\n\n\n\n\n\n\niscustomer    0    1\nregion              \nMidwest     207   17\nNortheast   488  113\nNorthwest   171   16\nSouth       171   20\nSouthwest   266   31\n\n\nBelow we see that the mean age of non-customers (iscustomer=0) is 26.69 years, while the mean age of customers (iscustomer=1) is 24.15 years.\nThis means that on avg. the firms using the software about 2.5 years younger.\n\nimport matplotlib.pyplot as plt\n\n#fig size\nplt.figure(figsize=(14, 7))\n\n#Create histogram for non-customers \nblue[blue['iscustomer'] == 0]['age'].hist(alpha=0.5, label='Non-Customers', bins=20, edgecolor='black')\n\n#Create histogram for customers\nblue[blue['iscustomer'] == 1]['age'].hist(alpha=0.5, label='Customers', bins=20, edgecolor='black')\n\n#Add title, labels, and legend\nplt.title('Distribution of Firm Age by Customer Status')\nplt.xlabel('Age Since Incorporation')\nplt.ylabel('Number of Firms')\nplt.legend()\n\nplt.show()\n\n#Calculate the mean age for each group \nage_means = blue.groupby('iscustomer')['age'].mean()\nprint(\"Mean Age by Customer Status:\")\nprint(age_means)\n\n\n\n\n\n\n\n\nMean Age by Customer Status:\niscustomer\n0    26.691481\n1    24.149746\nName: age, dtype: float64\n\n\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\n\n\n\n\n\n\nTODO\n\n\n\n\n\ntodo: Write down mathematically the likelihood for \\(Y \\sim \\text{Poisson}(\\lambda)\\). Note that \\(f(Y|\\lambda) = e^{-\\lambda}\\lambda^Y/Y!\\).\ntodo: Code the likelihood (or log-likelihood) function for the Poisson model. This is a function of lambda and Y. For example:\n\n\n\nThe function below calulates the possion likelihood of Y given the lambda. Lamda is the parameter of the posson distribution which must be greater than 0. Y is the array of variable we’re counting. The function itself will return the likelihood of Y given lambda.\n\ndef poisson_likelihood(lambda_, Y):\n    if lambda_ &lt;= 0:\n        raise ValueError(\"Lambda must be greater than 0\")\n    \n    # Calculate the Poisson probability for each Y_i\n    probabilities = (np.exp(-lambda_) * lambda_**Y) / np.array([np.math.factorial(y) for y in Y])\n\n    #Product of probabilities\n    return np.prod(probabilities)\n\n#inputs\nY = np.array([1, 0, 1, 3, 4, 2, 0])\nlambda_ = 1.9\n\n#likelihood\nlikelihood = poisson_likelihood(lambda_, Y)\nprint(\"Poisson Likelihood:\", likelihood)\n\nPoisson Likelihood: 6.772991232302341e-06\n\n\nC:\\Users\\kcrah\\AppData\\Local\\Temp\\ipykernel_21892\\1078196594.py:6: DeprecationWarning: `np.math` is a deprecated alias for the standard library `math` module (Deprecated Numpy 1.25). Replace usages of `np.math` with `math`\n  probabilities = (np.exp(-lambda_) * lambda_**Y) / np.array([np.math.factorial(y) for y in Y])\n\n\n\n\n\n\n\n\nTODO\n\n\n\n\n\ntodo: Use your function to plot lambda on the horizontal axis and the likelihood (or log-likelihood) on the vertical axis for a range of lambdas (use the observed number of patents as the input for Y).\ntodo: If you’re feeling mathematical, take the first derivative of your likelihood or log-likelihood, set it equal to zero and solve for lambda. You will find lambda_mle is Ybar, which “feels right” because the mean of a Poisson distribution is lambda.\ntodo: Find the MLE by optimizing your likelihood function with optim() in R or sp.optimize() in Python.\n\n\n\nUsing the function to plot lambda on the horizontal axis and the log likelihood on the vertical axis for a range of lambdas using the observed number of patents as the input for Y gets the following.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport math\n\ndef poisson_loglikelihood(lambda_, Y):\n    if lambda_ &lt;= 0:\n        return -np.inf  # Return negative infinity for non-positive lambda values to avoid computational errors\n    log_likelihood = -len(Y) * lambda_ + np.sum(Y * np.log(lambda_)) - np.sum([math.log(math.factorial(y)) for y in Y])\n    return log_likelihood\n\n#Set y to patent count \nY = blue['patents'].values  \n\n#Make a range of lambda from 0.1 to 10, with 100 points\nlambda_values = np.linspace(0.1, 10, 100)\nlog_likelihood_values = [poisson_loglikelihood(lam, Y) for lam in lambda_values]\n\n#Plot\nplt.figure(figsize=(10, 6))\nplt.plot(lambda_values, log_likelihood_values, label='Poisson Log-Likelihood')\nplt.title('Poisson Log-Likelihood vs. Lambda for Observed Patent Counts')\nplt.xlabel('Lambda')\nplt.ylabel('Log-Likelihood')\nplt.grid(True)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nTo Find the MLE I optimizied the likelihood functionsp.optimize().\n\nresult = optimize.minimize(\n    fun=poisson_loglikelihood,\n    x0=[1.0],  \n    args=(Y,),  \n    bounds=[(0.001, None)] \n)\n\nprint(\"MLE for lambda:\", result.x)\nprint(\"Optimization success:\", result.success)\nprint(\"Log-Likelihood at MLE:\", -result.fun)\n\nMLE for lambda: [0.001]\nOptimization success: True\nLog-Likelihood at MLE: 43229.55041700371\n\n\nWe see that the MLE = 0.001. This could be because of the initial guess, or constraints set in the optimization, or because its a log likelihood function.\nTo solve this I did the following - The initial guess was changed to the mean of the observed data - The function was modified to return the negative log-likelihood because scipy.optimize is designed to minimize functions. Therefore a negative will to maximize the original log-likelihood.\n\ndef poisson_loglikelihood_neg(lambda_, Y):\n    if lambda_ &lt;= 0:\n        return np.inf  \n    return -(-len(Y) * lambda_ + np.sum(Y * np.log(lambda_)) - np.sum([math.log(math.factorial(y)) for y in Y]))\n\nY = blue['patents'].values\n\n#get MLE with scipy.optimize.minimize\nresult = optimize.minimize(\n    fun=poisson_loglikelihood_neg,  \n    x0=[np.mean(Y)],  \n    args=(Y,), \n    bounds=[(0.001, None)], \n    options={'disp': True}  \n)\n\nprint(\"MLE for lambda:\", result.x)\nprint(\"Optimization success:\", result.success)\nprint(\"Log-Likelihood at MLE:\", -result.fun)\n\nMLE for lambda: [3.68466671]\nOptimization success: True\nLog-Likelihood at MLE: -3367.6837722350956\n\n\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\n\n\n\n\n\n\nTODO\n\n\n\n\n\ntodo: Update your likelihood or log-likelihood function with an additional argument to take in a covariate matrix X. Also change the parameter of the model from lambda to the beta vector. In this model, lambda must be a positive number, so we choose the inverse link function g() to be exp() so that \\(\\lambda_i = e^{X_i'\\beta}\\). For example:\n\n\n\n\ndef poisson_regression_loglikelihood(beta, X, Y):\n    #Set linear combination with inputs and parameters\n    linear_combination = X @ beta\n    \n    #Get lambda \n    lambda_i = np.exp(linear_combination)\n    \n    #Log-likelihood\n    log_likelihood = np.sum(-lambda_i + Y * np.log(lambda_i) - np.array([np.math.factorial(y) for y in Y]))\n    \n    return log_likelihood \n\n\n\n\n\n\n\nTODO\n\n\n\n\n\ntodo: Use your function along with R’s optim() or Python’s sp.optimize() to find the MLE vector and the Hessian of the Poisson model with covariates. Specifically, the first column of X should be all 1’s to enable a constant term in the model, and the subsequent columns should be age, age squared, binary variables for all but one of the regions, and the binary customer variable. Use the Hessian to find standard errors of the beta parameter estimates and present a table of coefficients and standard errors.\ntodo: Check your results using R’s glm() function or Python sm.GLM() function.\ntodo: Interpret the results. What do you conclude about the effect of Blueprinty’s software on patent success?\n\n\n\nFirst i used the function with sp.optimize() to find the MLE vector and the Hessian of the Poisson model with covariates. Using the Hessian to find standard errors of the beta parameter estimates and present a table of coefficients and standard errors.\n—————work——————————–\n\nimport numpy as np\nimport pandas as pd\nimport scipy.optimize as optimize\nimport scipy.special as sps\n\ndef poisson_regression_loglikelihood_neg(beta, X, Y):\n    eta = np.dot(X, beta)  \n    lambda_i = np.exp(eta.clip(-10, 10)) \n    log_likelihood = -np.sum(lambda_i - Y * np.log(lambda_i) + sps.gammaln(Y + 1))\n    return log_likelihood\n\n#Example setup of data\nnp.random.seed(0)\nn = 100  # number of observations\nX = np.random.normal(0, 1, (n, 3))  # example feature matrix with 3 features\nX[:, 0] = 1  # replace first column with 1s for the intercept\nbeta_true = np.array([0.5, -0.2, 0.1])  # true beta coefficients for simulation\nY = np.random.poisson(lam=np.exp(np.dot(X, beta_true)))  # simulate response variable\n\n#Initial guess for beta parameters\nbeta_init = np.zeros(X.shape[1])\n\n#Optimize to find MLE of beta using BFGS method\nresult = optimize.minimize(\n    fun=poisson_regression_loglikelihood_neg,\n    x0=beta_init,\n    args=(X, Y),\n    method='BFGS'\n)\n\n#Extract the standard errors \nstd_errors = np.sqrt(np.diag(result.hess_inv))\n\n#Results\ncoefficients = result.x\ncoeff_std_errors = np.vstack((coefficients, std_errors)).T\ncoeff_table = pd.DataFrame(coeff_std_errors, columns=['Coefficient', 'Std Error'],\n                           index=['Intercept', 'Feature1', 'Feature2'])\n\nprint(\"Optimization Success:\", result.success)\nprint(\"Estimated Beta Coefficients:\", result.x)\nprint(\"Standard Errors:\", std_errors)\nprint(\"Coefficient Table:\\n\", coeff_table)\n\nOptimization Success: True\nEstimated Beta Coefficients: [-4863.4308561   3763.13239674  -535.81789614]\nStandard Errors: [31.40710573 24.36727542  3.60740896]\nCoefficient Table:\n            Coefficient  Std Error\nIntercept -4863.430856  31.407106\nFeature1   3763.132397  24.367275\nFeature2   -535.817896   3.607409"
  },
  {
    "objectID": "homeworks/homework 2/index.html#introduction",
    "href": "homeworks/homework 2/index.html#introduction",
    "title": "HW 2",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nIn an effort to under stand “the economics of charity” Karlan and List found that a matching grant letter significantly boosts both revenue per solicitation and the likelihood of donationb by 19$ and 22$ respectively. The experiment itself, started by randomly assigning to either a control group or a matching grant treatment group, and within the matching grant treatment group individuals were randomly assigned to different matching grant rates, matching grant maximum amounts, and suggested donation amounts.\nIntrestingly larger matching ratios of $3:$1 and $2:$1 do not yield additional revenue when compared to the $1:$1 ratio. The study also considers spatial heterogeneity, finding that the influence of matching gifts varies significantly based on the political environment, with a stronger effect observed in red states that supported George W. Bush in the 2004 presidential election. This means that an individual’s political beliefs has influences the level of giving, and their responsiveness to different treatments.\nThe researchers state that this study and previosuly similar conducted studies are all of course hypothetical. Therefore they state that the study might be viewed as a useful test of scope using an approach consistent with natural provision of a real public good. However despite variations in outcomes across studies, the researchers state that all studies convey the complexity of charitable giving behavior and the need for further empirical investigation.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "homeworks/homework 2/index.html#data",
    "href": "homeworks/homework 2/index.html#data",
    "title": "HW 2",
    "section": "Data",
    "text": "Data\n\nDescription\n\n\nNote: you may need to restart the kernel to use updated packages.\n\n\n\n[notice] A new release of pip is available: 23.2.1 -&gt; 24.0\n[notice] To update, run: C:\\Users\\kcrah\\AppData\\Local\\Programs\\Python\\Python312\\pythonw.exe -m pip install --upgrade pip\n\n\n\n#Import libarary and data file\nimport pandas as pd\nfrom scipy.stats import ttest_ind\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndata = pd.read_stata(\"C:/Users/kcrah/Desktop/Quarto_stuff/files/karlan_list_2007.dta\")\n\n\ndata.head()\n\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.0\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.0\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.0\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.0\n\n\n\n\n5 rows × 51 columns\n\n\n\n\n\ndata.describe()\n\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio2\nratio3\nsize25\nsize50\nsize100\nsizeno\naskd1\naskd2\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\ncount\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n...\n49978.000000\n49978.000000\n48217.000000\n48047.000000\n48217.000000\n48221.000000\n48209.000000\n48214.000000\n48215.000000\n48217.000000\n\n\nmean\n0.666813\n0.333187\n0.222311\n0.222211\n0.166723\n0.166623\n0.166723\n0.166743\n0.222311\n0.222291\n...\n0.510245\n0.488715\n0.819599\n0.086710\n0.321694\n2.429012\n54815.700533\n0.669418\n0.391661\n0.871968\n\n\nstd\n0.471357\n0.471357\n0.415803\n0.415736\n0.372732\n0.372643\n0.372732\n0.372750\n0.415803\n0.415790\n...\n0.499900\n0.499878\n0.168561\n0.135868\n0.103039\n0.378115\n22027.316665\n0.193405\n0.186599\n0.258654\n\n\nmin\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.009418\n0.000000\n0.000000\n0.000000\n5000.000000\n0.000000\n0.000000\n0.000000\n\n\n25%\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.755845\n0.014729\n0.258311\n2.210000\n39181.000000\n0.560222\n0.235647\n0.884929\n\n\n50%\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n0.000000\n0.872797\n0.036554\n0.305534\n2.440000\n50673.000000\n0.712296\n0.373744\n1.000000\n\n\n75%\n1.000000\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n1.000000\n0.938827\n0.090882\n0.369132\n2.660000\n66005.000000\n0.816798\n0.530036\n1.000000\n\n\nmax\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n...\n1.000000\n1.000000\n1.000000\n0.989622\n0.997544\n5.270000\n200001.000000\n1.000000\n1.000000\n1.000000\n\n\n\n\n8 rows × 48 columns\n\n\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\n\n\n\n\nBalance Test\n\n\n\n\n\ntodo: test a few variables other than the key outcome variables (for example, test months since last donation) to see if the treatment and control groups are statistically significantly different at the 95% confidence level. Do each as a t-test and separately as a linear regression, and confirm you get the exact same results from both methods. When doing a t-test, use the formula in the class slides. When doing the linear regression, regress for example mrm2 on treatment and look at the estimated coefficient on the treatment variable. It might be helpful to compare parts of your analysis to Table 1 in the paper. Be sure to comment on your results (hint: why is Table 1 included in the paper).\n\n\n\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\nFirst I did a t-test to compare the mrm2 between the treatment and control groups to determine if there are any statistically significant differences at the 95% confidence level.\n\n#Getting data for t-test and linear regression\ntreatment_mrm2 = data[data['treatment'] == 1]['mrm2']\ncontrol_mrm2 = data[data['treatment'] == 0]['mrm2']\n\n\n#T-test\nt_test_result = ttest_ind(treatment_mrm2.dropna(), control_mrm2.dropna(), equal_var=False)\nt_test_result\n\nTtestResult(statistic=0.11953155228177251, pvalue=0.9048549631450832, df=33394.47581389535)\n\n\nThen I did a linear regression to again compare the mrm2 between the treatment and control groups to determine if there are any statistically significant differences at the 95% confidence level.\n\n#Data for linear regression\nX = sm.add_constant(data['treatment'])  # Adding a constant for the intercept\ny = data['mrm2'].dropna()\nX = X[X.index.isin(y.index)]  #Match index in X and y after dropping 'NA' in y\n\n\n#Linear regression\nmodel = sm.OLS(y, X)\nresults = model.fit()\n\n\nt_test_result, results.summary()\n\n(TtestResult(statistic=0.11953155228177251, pvalue=0.9048549631450832, df=33394.47581389535),\n &lt;class 'statsmodels.iolib.summary.Summary'&gt;\n \"\"\"\n                             OLS Regression Results                            \n ==============================================================================\n Dep. Variable:                   mrm2   R-squared:                       0.000\n Model:                            OLS   Adj. R-squared:                 -0.000\n Method:                 Least Squares   F-statistic:                   0.01428\n Date:                Mon, 29 Apr 2024   Prob (F-statistic):              0.905\n Time:                        16:22:34   Log-Likelihood:            -1.9585e+05\n No. Observations:               50082   AIC:                         3.917e+05\n Df Residuals:                   50080   BIC:                         3.917e+05\n Df Model:                           1                                         \n Covariance Type:            nonrobust                                         \n ==============================================================================\n                  coef    std err          t      P&gt;|t|      [0.025      0.975]\n ------------------------------------------------------------------------------\n const         12.9981      0.094    138.979      0.000      12.815      13.181\n treatment      0.0137      0.115      0.119      0.905      -0.211       0.238\n ==============================================================================\n Omnibus:                     8031.352   Durbin-Watson:                   2.004\n Prob(Omnibus):                  0.000   Jarque-Bera (JB):            12471.135\n Skew:                           1.163   Prob(JB):                         0.00\n Kurtosis:                       3.751   Cond. No.                         3.23\n ==============================================================================\n \n Notes:\n [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n \"\"\")\n\n\n\nT-Test Results:\n\nStatistic: 0.120\nP-value: 0.905\n\nThe t-test results indicate that there is no statistically significant difference in the months since the last donation between the treatment and control groups (p-value &gt; 0.05).\n\n\nLinear Regression Results:\n\nCoefficient for treatment: 0.0137\nStandard error: 0.115\nP-value: 0.905\n\nThe linear regression, shows a statistically insignificant coefficient for the treatment variable when p-value &gt; 0.05. No impact of the treatment on the months since last donation."
  },
  {
    "objectID": "homeworks/homework 2/index.html#experimental-results",
    "href": "homeworks/homework 2/index.html#experimental-results",
    "title": "HW 2",
    "section": "Experimental Results",
    "text": "Experimental Results\n\n\n\n\n\n\nCharitable Contribution Made\n\n\n\n\n\ntodo: make a barplot with two bars. Each bar is the proportion of people who donated. One bar for treatment and one bar for control.\ntodo: run a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made. Also run a bivariate linear regression that demonstrates the same finding. (It may help to confirm your calculations match Table 2a Panel A.) Report your statistical results and interpret them in the context of the experiment (e.g., if you found a difference with a small p-value or that was statistically significant at some threshold, what have you learned about human behavior? Use mostly English words, not numbers or stats, to explain your finding.)\ntodo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control. Confirm that your results replicate Table 3 column 1 in the paper.\n\n\n\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\nI started by making a bar plot. Each bar is the proportion of people who donated. One bar for treatment and one bar for control.\n\nimport matplotlib.pyplot as plt\n\n#Calculate the proportion of donors in treatment and control groups\ndonor_proportion_treatment = data[data['treatment'] == 1]['gave'].mean()\ndonor_proportion_control = data[data['treatment'] == 0]['gave'].mean()\n\n#Lable and prop\nlabels = ['Treatment', 'Control']\nproportions = [donor_proportion_treatment, donor_proportion_control]\n\n#Bar plot\nplt.figure(figsize=(8, 5))\nbars = plt.bar(labels, proportions, color=['blue', 'green'])\n\n#Adding percentage labels above the bars\nfor bar in bars:\n    yval = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2, yval, f'{yval:.2%}', ha='center', va='bottom', fontsize=12)\n\nplt.ylabel('Proportion Who Donated')\nplt.title('Proportion of People Who Donated by Group')\nplt.show()\n\n\n\n\n\n\n\n\nThe bar graph above shows that in the treatment group 2.20% of the participants made a donation. In the control group 1.79% of the participants donated.\nNext I ran a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made.\n\n#Match data for t-test on the binary outcome 'gave'\ngave_treatment = data[data['treatment'] == 1]['gave']\ngave_control = data[data['treatment'] == 0]['gave']\n\n\n#T-test\nt_test_gave_result = ttest_ind(gave_treatment.dropna(), gave_control.dropna(), equal_var=False)\nt_test_gave_result\n\nTtestResult(statistic=3.2094621908279835, pvalue=0.001330982345091417, df=36576.84238986656)\n\n\n\nt-test: 3.209\n\n\np-val: 0.0013\nThis shows a statistically significant difference between the treatment and control groups as shown by the p-value being below 0.05 meaning we reject the null hypothesis.\nI also ran a bivariate linear regression that demonstrates the same finding.\n\n#Matching data for linear regression\nX_gave = sm.add_constant(data['treatment'])  #Adding a constant for the intercept\ny_gave = data['gave'].dropna()\nX_gave = X_gave[X_gave.index.isin(y_gave.index)]  #Match index in X and y after dropping 'NA' in y\n\n\n# Linear regression\nmodel_gave = sm.OLS(y_gave, X_gave)\nresults_gave = model_gave.fit()\n\n\nt_test_gave_result, results_gave.summary()\n\n(TtestResult(statistic=3.2094621908279835, pvalue=0.001330982345091417, df=36576.84238986656),\n &lt;class 'statsmodels.iolib.summary.Summary'&gt;\n \"\"\"\n                             OLS Regression Results                            \n ==============================================================================\n Dep. Variable:                   gave   R-squared:                       0.000\n Model:                            OLS   Adj. R-squared:                  0.000\n Method:                 Least Squares   F-statistic:                     9.618\n Date:                Mon, 29 Apr 2024   Prob (F-statistic):            0.00193\n Time:                        16:22:34   Log-Likelihood:                 26630.\n No. Observations:               50083   AIC:                        -5.326e+04\n Df Residuals:                   50081   BIC:                        -5.324e+04\n Df Model:                           1                                         \n Covariance Type:            nonrobust                                         \n ==============================================================================\n                  coef    std err          t      P&gt;|t|      [0.025      0.975]\n ------------------------------------------------------------------------------\n const          0.0179      0.001     16.225      0.000       0.016       0.020\n treatment      0.0042      0.001      3.101      0.002       0.002       0.007\n ==============================================================================\n Omnibus:                    59814.280   Durbin-Watson:                   2.005\n Prob(Omnibus):                  0.000   Jarque-Bera (JB):          4317152.727\n Skew:                           6.740   Prob(JB):                         0.00\n Kurtosis:                      46.440   Cond. No.                         3.23\n ==============================================================================\n \n Notes:\n [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n \"\"\")\n\n\n\n\nCoefficient for treatment: 0.0042\n\n\nP-value: 0.002\nThe bivariate linear regression, by regressing the binary outcome ‘gave’, on the treatment variable shows a positive coefficient for treatment of 0.0042. This means it’s statistically significant, which matchs the aforementioned t-test.\n\n\nHuman Behavior\nThis shows the treatment group had a higher proportion people who donated than the control group, by 0.42%, as shown by the treatment regression coefficient.This means that the treatment of a matching grant letter is enough to persuage some into donating.\n\n\n\n\n\n\nDifferences between Match Rates\n\n\n\n\n\ntodo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the “figures suggest” comment the authors make on page 8?\ntodo: Assess the same issue using a regression. Specifically, create the variable ratio1 then regress gave on ratio1, ratio2, and ratio3 (or alternatively, regress gave on the categorical variable ratio). Interpret the coefficients and their statistical precision.\ntodo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?\n\n\n\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\nI started by using a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate?\n\n# Get data for the 2:1 match rate group \nratio2_sample = data[data['ratio2'] == 1]\nratio2_sample\n\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n7\n1\n0\n2\n1\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.903297\n0.019494\n0.212040\n2.47\n141527.0\n0.897906\n0.708122\n1.000000\n\n\n8\n1\n0\n2\n1\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.927851\n0.004739\n0.249465\n2.49\n37017.0\n0.763151\n0.205828\n0.599052\n\n\n11\n1\n0\n2\n1\n0\n$50,000\n0\n1\n0\n0\n...\n1.0\n0.0\n0.816659\n0.042910\n0.345686\n2.35\n50163.0\n0.468334\n0.254896\n1.000000\n\n\n13\n1\n0\n2\n1\n0\n$25,000\n1\n0\n0\n0\n...\n1.0\n0.0\n0.967608\n0.015739\n0.284836\n2.85\n67859.0\n0.883114\n0.405628\n0.970737\n\n\n19\n1\n0\n2\n1\n0\n$25,000\n1\n0\n0\n0\n...\n1.0\n0.0\n0.904871\n0.004875\n0.273782\n2.70\n41553.0\n0.726801\n0.181954\n0.922775\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n50055\n1\n0\n2\n1\n0\n$25,000\n1\n0\n0\n0\n...\n1.0\n0.0\n0.585023\n0.304967\n0.267524\n2.86\n74903.0\n0.828101\n0.478660\n1.000000\n\n\n50059\n1\n0\n2\n1\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.582680\n0.193563\n0.451955\n2.02\n34293.0\n0.325738\n0.391760\n1.000000\n\n\n50064\n1\n0\n2\n1\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.848056\n0.036633\n0.193733\n2.65\n113788.0\n0.851489\n0.774322\n1.000000\n\n\n50074\n1\n0\n2\n1\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.907267\n0.029272\n0.288404\n2.97\n66051.0\n0.884930\n0.276022\n0.979433\n\n\n50075\n1\n0\n2\n1\n0\nUnstated\n0\n0\n0\n1\n...\n0.0\n1.0\n0.526869\n0.010935\n0.287106\n2.76\n100020.0\n0.640149\n0.650302\n0.990903\n\n\n\n\n11134 rows × 51 columns\n\n\n\n\n\n# Get  data for the 1:1 match rate group \nratio1_sample = data[data['ratio'] == 1]\nratio1_sample\n\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.000000\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.000000\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.000000\n\n\n6\n1\n0\n1\n0\n0\n$25,000\n1\n0\n0\n0\n...\n1.0\n0.0\n0.882912\n0.097408\n0.376446\n2.10\n54655.0\n0.695880\n0.554568\n1.000000\n\n\n9\n1\n0\n1\n0\n0\n$25,000\n1\n0\n0\n0\n...\n0.0\n1.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n50058\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.877152\n0.061334\n0.453103\n2.60\n62258.0\n0.702048\n0.481502\n0.986119\n\n\n50060\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.807919\n0.121061\n0.353253\n2.17\n40867.0\n0.743756\n0.351826\n1.000000\n\n\n50065\n1\n0\n1\n0\n0\n$25,000\n1\n0\n0\n0\n...\n0.0\n1.0\n0.902345\n0.056393\n0.265941\n1.98\n48920.0\n0.649136\n0.400955\n1.000000\n\n\n50066\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.410729\n0.040790\n0.376367\n3.24\n30152.0\n0.250095\n0.123647\n1.000000\n\n\n50078\n1\n0\n1\n0\n0\n$25,000\n1\n0\n0\n0\n...\n0.0\n1.0\n0.872797\n0.089959\n0.257265\n2.13\n45047.0\n0.771316\n0.263744\n1.000000\n\n\n\n\n11133 rows × 51 columns\n\n\n\n\n\n# Match data for t-tests comparing different match ratios\ngave_ratio1 = data[data['ratio'] == '1']['gave']\ngave_ratio2 = data[data['ratio2'] == 1]['gave']\n\n\n# Calc t-test for ratios\nt_test_ratio1_vs_ratio2 = ttest_ind(gave_ratio1.dropna(), gave_ratio2.dropna(), equal_var=False)\n\nt_test_ratio1_vs_ratio2\n\nTtestResult(statistic=nan, pvalue=nan, df=nan)\n\n\n#not getting pvals ——————————\n\n\n\n\n\n\nSize of Charitable Contribution\n\n\n\n\n\ntodo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?\ntodo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients – what did we learn? Does the treatment coefficient have a causal interpretation?\ntodo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot.\n\n\n\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution…\nI started by doing a t-test on the donation amount based on treatment status, to see if there’s a statistically significant difference in the amount donated between the treatment group and the control group.\n\n#Get donation amounts for treatment and control groups\ntreatment_amounts = data[data['treatment'] == 1]['amount']\ncontrol_amounts = data[data['treatment'] == 0]['amount']\n\n#t-test between the two groups\nt_test_results = ttest_ind(treatment_amounts.dropna(), control_amounts.dropna(), equal_var=False)\n\nt_test_results\n\nTtestResult(statistic=1.9182618934467577, pvalue=0.055085665289183336, df=36216.05660774625)\n\n\n\n\nt-test: 1.92\n\n\np-val: 0.06\nThe t-test shows that the treatment mean donation the control group, with the difference being 1.918. The p-val of 0.06 which is higher than 0.05 means there is a small difference in the means of the donation amounts between the treatment and control groups."
  },
  {
    "objectID": "homeworks/homework 2/index.html#simulation-experiment",
    "href": "homeworks/homework 2/index.html#simulation-experiment",
    "title": "HW 2",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\n\n\n\n\n\nLaw of Large Numbers\n\n\n\n\n\nto do: Make a plot like those on slide 43 from our first class and explain the plot to the reader. To do this, you will simulate 100,000 draws from the control distribution and 10,000 draws from the treatment distribution. You’ll then calculate a vector of 10,000 differences, and then you’ll plot the cumulative average of that vector of differences. Comment on whether the cumulative average approaches the true difference in means.\n\n\n\nFirst I made a plot like those on slide 43 from our first class. The plot shows…\nThis was done by simulating 100,000 draws from the control distribution and 10,000 draws from the treatment distribution. I then calculated a vector of 10,000 differences, and then I ploted the cumulative average of the vector of differences. The cumulative average approaches the true difference in means because…\n\n\n\n\n\n\nCentral Limit Theorem\n\n\n\n\n\nto do: Make 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 and explain these plots to the reader. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. Comment on whether zero is in the “middle” of the distribution or whether it’s in the “tail.”\n\n\n\nI made 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 which show… I did this for sample size 50,200,500 and 1000 by taking the respective sample draws from each of the control and treatment distributions, and calculating the average difference between those draws. Then repeating that process 999 more times so I had 1000 averages. The zero is the “middle” of the distribution for all 4 histograms.\n\n#Calculate means and standard deviations for 'gave' \ntreatment_gave = data[data['treatment'] == 1]['gave']\ncontrol_gave = data[data['treatment'] == 0]['gave']\n\nmean_treatment = treatment_gave.mean()\nmean_control = control_gave.mean()\nstd_treatment = treatment_gave.std()\nstd_control = control_gave.std()\n\n#Show mean and std dev for treat and control\nprint(\"Treatment Mean:\", mean_treatment, \"Control Mean:\", mean_control)\n\nprint(\"Treatment Std Dev:\", std_treatment, \"Control Std Dev:\", std_control)\n\nTreatment Mean: 0.02203856749311295 Control Mean: 0.017858212980164198\nTreatment Std Dev: 0.14681115226051514 Control Std Dev: 0.13243998017151457\n\n\n\n#Function to simulate differences\ndef simulate_differences(sample_size, num_simulations):\n    differences = []\n    for _ in range(num_simulations):\n        treatment_sample = np.random.binomial(1, mean_treatment, sample_size)\n        control_sample = np.random.binomial(1, mean_control, sample_size)\n        differences.append(treatment_sample.mean() - control_sample.mean())\n    return differences\n\n#Get sample size and 1000 simulation\nsample_sizes = [50, 200, 500, 1000]\nnum_simulations = 1000\n\n#Make 4 histograms\nfor size in sample_sizes:\n    diffs = simulate_differences(size, num_simulations)\n    plt.figure()\n    plt.hist(diffs, bins=30, alpha=0.75, color='blue')\n    plt.axvline(x=0, color='red', linestyle='--', label='Zero')\n    plt.title(f'Histogram of Differences for Sample Size {size}')\n    plt.xlabel('Difference in Proportions')\n    plt.ylabel('Frequency')\n    plt.legend()\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHistogram Explanation:\nAll 4 histrograms show the zero line is at 0.0. This means that there is no statistically significant effect of the treatment on the measured outcome across the sampled observations."
  },
  {
    "objectID": "homeworks/homework 2/index.html#blueprinty-case-study",
    "href": "homeworks/homework 2/index.html#blueprinty-case-study",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\n\n\n\nData\n\n\n\n\n\ntodo: Read in data.\ntodo: Compare histograms and means of number of patents by customer status. What do you observe?\n\n\n\n\n\nNote: you may need to restart the kernel to use updated packages.\n\n\n\n[notice] A new release of pip is available: 23.2.1 -&gt; 24.0\n[notice] To update, run: C:\\Users\\kcrah\\AppData\\Local\\Programs\\Python\\Python312\\pythonw.exe -m pip install --upgrade pip\n\n\n\n#Import libarary and data file\nimport pandas as pd\nfrom scipy.stats import ttest_ind\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport math  \nimport scipy.optimize as optimize\nimport scipy.stats as stats\nimport pandas as pd\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\nair = pd.read_csv(\"C:/Users/kcrah/Desktop/Quarto_stuff/files/airbnb.csv\")\nblue = pd.read_csv(\"C:/Users/kcrah/Desktop/Quarto_stuff/files/blueprinty.csv\")\n\n\nblue.head()\n\n\n\n\n\n\n\n\n\nUnnamed: 0\npatents\nregion\nage\niscustomer\n\n\n\n\n0\n1\n0\nMidwest\n32.5\n0\n\n\n1\n786\n3\nSouthwest\n37.5\n0\n\n\n2\n348\n4\nNorthwest\n27.0\n1\n\n\n3\n927\n3\nNortheast\n24.5\n0\n\n\n4\n830\n3\nSouthwest\n37.0\n0\n\n\n\n\n\n\n\n\n\nblue.describe()\n\n\n\n\n\n\n\n\n\nUnnamed: 0\npatents\nage\niscustomer\n\n\n\n\ncount\n1500.000000\n1500.000000\n1500.000000\n1500.000000\n\n\nmean\n750.500000\n3.684667\n26.357667\n0.131333\n\n\nstd\n433.157015\n2.352500\n7.242528\n0.337877\n\n\nmin\n1.000000\n0.000000\n9.000000\n0.000000\n\n\n25%\n375.750000\n2.000000\n21.000000\n0.000000\n\n\n50%\n750.500000\n3.000000\n26.000000\n0.000000\n\n\n75%\n1125.250000\n5.000000\n31.625000\n0.000000\n\n\nmax\n1500.000000\n16.000000\n49.000000\n1.000000\n\n\n\n\n\n\n\n\nFirst I compare histograms and means of number of patents by customer status. I observe that the mean of non customers (iscustomer=0) is 3.62 and the mean of customers (iscustomer=1) is 4.09.\nThis means firms using the software have a higher average number of patents to firms that don’t.\n\n#Calculate the mean number of patents for customers and non-customers\nmeans = blue.groupby('iscustomer')['patents'].mean()\n\n#Create histograms to compare the distribution of patents\nplt.figure(figsize=(10, 6))\nblue[blue['iscustomer'] == 1]['patents'].hist(alpha=0.5, label='Customers', bins=20)\nblue[blue['iscustomer'] == 0]['patents'].hist(alpha=0.5, label='Non-Customers', bins=20)\nplt.title('Histogram of Number of Patents by Customer Status')\nplt.xlabel('Number of Patents')\nplt.ylabel('Frequency')\nplt.legend()\nplt.show()\n\nprint(means)\n\n\n\n\n\n\n\n\niscustomer\n0    3.623177\n1    4.091371\nName: patents, dtype: float64\n\n\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\nTherefore I compared regions and ages by customer status.\n\n\n\n\n\n\nTODO\n\n\n\n\n\ntodo: Compare regions and ages by customer status. What do you observe?\n\n\n\nWe see below that the number of non-customers is far greater than the number of customers for all regions. The ‘1’ representing customers and ‘0’ representing non-customers.\n\n#Accounting missing data for cols 'region' and 'age'\nblue['region'] = blue['region'].fillna('Unknown')\nblue['age'] = blue['age'].fillna(blue['age'].mean())\n\n#Compare regions by customer status\nregion_summary = blue.groupby(['region', 'iscustomer']).size().unstack(fill_value=0)\n\n#Plott regional distribution by customer status\nregion_summary.plot(kind='bar', figsize=(14, 7), stacked=True)\nplt.title('Distribution of Firms by Region and Customer Status')\nplt.xlabel('Region')\nplt.ylabel('Number of Firms')\nplt.legend(title='Customer Status', labels=['Non-Customers', 'Customers'])\nplt.xticks(rotation=45)\nplt.show()\n\n#Group by 'region' and 'iscustomer' and get count of firms\nregion_customer_counts = blue.groupby(['region', 'iscustomer']).size().unstack(fill_value=0)\n\nprint(region_customer_counts)\n\n\n\n\n\n\n\n\niscustomer    0    1\nregion              \nMidwest     207   17\nNortheast   488  113\nNorthwest   171   16\nSouth       171   20\nSouthwest   266   31\n\n\nBelow we see that the mean age of non-customers (iscustomer=0) is 26.69 years, while the mean age of customers (iscustomer=1) is 24.15 years.\nThis means that on avg. the firms using the software about 2.5 years younger.\n\nimport matplotlib.pyplot as plt\n\n#fig size\nplt.figure(figsize=(14, 7))\n\n#Create histogram for non-customers \nblue[blue['iscustomer'] == 0]['age'].hist(alpha=0.5, label='Non-Customers', bins=20, edgecolor='black')\n\n#Create histogram for customers\nblue[blue['iscustomer'] == 1]['age'].hist(alpha=0.5, label='Customers', bins=20, edgecolor='black')\n\n#Add title, labels, and legend\nplt.title('Distribution of Firm Age by Customer Status')\nplt.xlabel('Age Since Incorporation')\nplt.ylabel('Number of Firms')\nplt.legend()\n\nplt.show()\n\n#Calculate the mean age for each group \nage_means = blue.groupby('iscustomer')['age'].mean()\nprint(\"Mean Age by Customer Status:\")\nprint(age_means)\n\n\n\n\n\n\n\n\nMean Age by Customer Status:\niscustomer\n0    26.691481\n1    24.149746\nName: age, dtype: float64\n\n\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\n\n\n\n\n\n\nTODO\n\n\n\n\n\ntodo: Write down mathematically the likelihood for \\(Y \\sim \\text{Poisson}(\\lambda)\\). Note that \\(f(Y|\\lambda) = e^{-\\lambda}\\lambda^Y/Y!\\).\ntodo: Code the likelihood (or log-likelihood) function for the Poisson model. This is a function of lambda and Y. For example:\n\n\n\nThe function below calulates the possion likelihood of Y given the lambda. Lamda is the parameter of the posson distribution which must be greater than 0. Y is the array of variable we’re counting. The function itself will return the likelihood of Y given lambda.\n\ndef poisson_likelihood(lambda_, Y):\n    if lambda_ &lt;= 0:\n        raise ValueError(\"Lambda must be greater than 0\")\n    \n    # Calculate the Poisson probability for each Y_i\n    probabilities = (np.exp(-lambda_) * lambda_**Y) / np.array([np.math.factorial(y) for y in Y])\n\n    #Product of probabilities\n    return np.prod(probabilities)\n\n#inputs\nY = np.array([1, 0, 1, 3, 4, 2, 0])\nlambda_ = 1.9\n\n#likelihood\nlikelihood = poisson_likelihood(lambda_, Y)\nprint(\"Poisson Likelihood:\", likelihood)\n\nPoisson Likelihood: 6.772991232302341e-06\n\n\nC:\\Users\\kcrah\\AppData\\Local\\Temp\\ipykernel_21892\\1078196594.py:6: DeprecationWarning: `np.math` is a deprecated alias for the standard library `math` module (Deprecated Numpy 1.25). Replace usages of `np.math` with `math`\n  probabilities = (np.exp(-lambda_) * lambda_**Y) / np.array([np.math.factorial(y) for y in Y])\n\n\n\n\n\n\n\n\nTODO\n\n\n\n\n\ntodo: Use your function to plot lambda on the horizontal axis and the likelihood (or log-likelihood) on the vertical axis for a range of lambdas (use the observed number of patents as the input for Y).\ntodo: If you’re feeling mathematical, take the first derivative of your likelihood or log-likelihood, set it equal to zero and solve for lambda. You will find lambda_mle is Ybar, which “feels right” because the mean of a Poisson distribution is lambda.\ntodo: Find the MLE by optimizing your likelihood function with optim() in R or sp.optimize() in Python.\n\n\n\nUsing the function to plot lambda on the horizontal axis and the log likelihood on the vertical axis for a range of lambdas using the observed number of patents as the input for Y gets the following.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport math\n\ndef poisson_loglikelihood(lambda_, Y):\n    if lambda_ &lt;= 0:\n        return -np.inf  # Return negative infinity for non-positive lambda values to avoid computational errors\n    log_likelihood = -len(Y) * lambda_ + np.sum(Y * np.log(lambda_)) - np.sum([math.log(math.factorial(y)) for y in Y])\n    return log_likelihood\n\n#Set y to patent count \nY = blue['patents'].values  \n\n#Make a range of lambda from 0.1 to 10, with 100 points\nlambda_values = np.linspace(0.1, 10, 100)\nlog_likelihood_values = [poisson_loglikelihood(lam, Y) for lam in lambda_values]\n\n#Plot\nplt.figure(figsize=(10, 6))\nplt.plot(lambda_values, log_likelihood_values, label='Poisson Log-Likelihood')\nplt.title('Poisson Log-Likelihood vs. Lambda for Observed Patent Counts')\nplt.xlabel('Lambda')\nplt.ylabel('Log-Likelihood')\nplt.grid(True)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nTo Find the MLE I optimizied the likelihood functionsp.optimize().\n\nresult = optimize.minimize(\n    fun=poisson_loglikelihood,\n    x0=[1.0],  \n    args=(Y,),  \n    bounds=[(0.001, None)] \n)\n\nprint(\"MLE for lambda:\", result.x)\nprint(\"Optimization success:\", result.success)\nprint(\"Log-Likelihood at MLE:\", -result.fun)\n\nMLE for lambda: [0.001]\nOptimization success: True\nLog-Likelihood at MLE: 43229.55041700371\n\n\nWe see that the MLE = 0.001. This could be because of the initial guess, or constraints set in the optimization, or because its a log likelihood function.\nTo solve this I did the following - The initial guess was changed to the mean of the observed data - The function was modified to return the negative log-likelihood because scipy.optimize is designed to minimize functions. Therefore a negative will to maximize the original log-likelihood.\n\ndef poisson_loglikelihood_neg(lambda_, Y):\n    if lambda_ &lt;= 0:\n        return np.inf  \n    return -(-len(Y) * lambda_ + np.sum(Y * np.log(lambda_)) - np.sum([math.log(math.factorial(y)) for y in Y]))\n\nY = blue['patents'].values\n\n#get MLE with scipy.optimize.minimize\nresult = optimize.minimize(\n    fun=poisson_loglikelihood_neg,  \n    x0=[np.mean(Y)],  \n    args=(Y,), \n    bounds=[(0.001, None)], \n    options={'disp': True}  \n)\n\nprint(\"MLE for lambda:\", result.x)\nprint(\"Optimization success:\", result.success)\nprint(\"Log-Likelihood at MLE:\", -result.fun)\n\nMLE for lambda: [3.68466671]\nOptimization success: True\nLog-Likelihood at MLE: -3367.6837722350956\n\n\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\n\n\n\n\n\n\nTODO\n\n\n\n\n\ntodo: Update your likelihood or log-likelihood function with an additional argument to take in a covariate matrix X. Also change the parameter of the model from lambda to the beta vector. In this model, lambda must be a positive number, so we choose the inverse link function g() to be exp() so that \\(\\lambda_i = e^{X_i'\\beta}\\). For example:\n\n\n\n\ndef poisson_regression_loglikelihood(beta, X, Y):\n    #Set linear combination with inputs and parameters\n    linear_combination = X @ beta\n    \n    #Get lambda \n    lambda_i = np.exp(linear_combination)\n    \n    #Log-likelihood\n    log_likelihood = np.sum(-lambda_i + Y * np.log(lambda_i) - np.array([np.math.factorial(y) for y in Y]))\n    \n    return log_likelihood \n\n\n\n\n\n\n\nTODO\n\n\n\n\n\ntodo: Use your function along with R’s optim() or Python’s sp.optimize() to find the MLE vector and the Hessian of the Poisson model with covariates. Specifically, the first column of X should be all 1’s to enable a constant term in the model, and the subsequent columns should be age, age squared, binary variables for all but one of the regions, and the binary customer variable. Use the Hessian to find standard errors of the beta parameter estimates and present a table of coefficients and standard errors.\ntodo: Check your results using R’s glm() function or Python sm.GLM() function.\ntodo: Interpret the results. What do you conclude about the effect of Blueprinty’s software on patent success?\n\n\n\nFirst i used the function with sp.optimize() to find the MLE vector and the Hessian of the Poisson model with covariates. Using the Hessian to find standard errors of the beta parameter estimates and present a table of coefficients and standard errors.\n—————work——————————–\n\nimport numpy as np\nimport pandas as pd\nimport scipy.optimize as optimize\nimport scipy.special as sps\n\ndef poisson_regression_loglikelihood_neg(beta, X, Y):\n    eta = np.dot(X, beta)  \n    lambda_i = np.exp(eta.clip(-10, 10)) \n    log_likelihood = -np.sum(lambda_i - Y * np.log(lambda_i) + sps.gammaln(Y + 1))\n    return log_likelihood\n\n#Example setup of data\nnp.random.seed(0)\nn = 100  # number of observations\nX = np.random.normal(0, 1, (n, 3))  # example feature matrix with 3 features\nX[:, 0] = 1  # replace first column with 1s for the intercept\nbeta_true = np.array([0.5, -0.2, 0.1])  # true beta coefficients for simulation\nY = np.random.poisson(lam=np.exp(np.dot(X, beta_true)))  # simulate response variable\n\n#Initial guess for beta parameters\nbeta_init = np.zeros(X.shape[1])\n\n#Optimize to find MLE of beta using BFGS method\nresult = optimize.minimize(\n    fun=poisson_regression_loglikelihood_neg,\n    x0=beta_init,\n    args=(X, Y),\n    method='BFGS'\n)\n\n#Extract the standard errors \nstd_errors = np.sqrt(np.diag(result.hess_inv))\n\n#Results\ncoefficients = result.x\ncoeff_std_errors = np.vstack((coefficients, std_errors)).T\ncoeff_table = pd.DataFrame(coeff_std_errors, columns=['Coefficient', 'Std Error'],\n                           index=['Intercept', 'Feature1', 'Feature2'])\n\nprint(\"Optimization Success:\", result.success)\nprint(\"Estimated Beta Coefficients:\", result.x)\nprint(\"Standard Errors:\", std_errors)\nprint(\"Coefficient Table:\\n\", coeff_table)\n\nOptimization Success: True\nEstimated Beta Coefficients: [-4863.4308561   3763.13239674  -535.81789614]\nStandard Errors: [31.40710573 24.36727542  3.60740896]\nCoefficient Table:\n            Coefficient  Std Error\nIntercept -4863.430856  31.407106\nFeature1   3763.132397  24.367275\nFeature2   -535.817896   3.607409"
  },
  {
    "objectID": "homeworks/homework 2/index.html#airbnb-case-study",
    "href": "homeworks/homework 2/index.html#airbnb-case-study",
    "title": "Poisson Regression Examples",
    "section": "AirBnB Case Study",
    "text": "AirBnB Case Study\n\nIntroduction\nAirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped of 40,000 Airbnb listings from New York City. The data include the following variables:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n- `id` = unique ID number for each unit\n- `last_scraped` = date when information scraped\n- `host_since` = date when host first listed the unit on Airbnb\n- `days` = `last_scraped` - `host_since` = number of days the unit has been listed\n- `room_type` = Entire home/apt., Private room, or Shared room\n- `bathrooms` = number of bathrooms\n- `bedrooms` = number of bedrooms\n- `price` = price per night (dollars)\n- `number_of_reviews` = number of reviews for the unit on Airbnb\n- `review_scores_cleanliness` = a cleanliness score from reviews (1-10)\n- `review_scores_location` = a \"quality of location\" score from reviews (1-10)\n- `review_scores_value` = a \"quality of value\" score from reviews (1-10)\n- `instant_bookable` = \"t\" if instantly bookable, \"f\" if not\n\n\n\n\n\n\n\n\n\nTODO\n\n\n\n\n\ntodo: Assume the number of reviews is a good proxy for the number of bookings. Perform some exploratory data analysis to get a feel for the data, handle or drop observations with missing values on relevant variables, build one or more models (e.g., a poisson regression model for the number of bookings as proxied by the number of reviews), and interpret model coefficients to describe variation in the number of reviews as a function of the variables provided.\n\n\n\n\nair = pd.read_csv(\"C:/Users/kcrah/Desktop/Quarto_stuff/files/airbnb.csv\")\n\n\n\nExploratory Data Analysis\n\nprint(air.head())\nprint(air.isnull().sum())\nprint(air.describe())\n\n   Unnamed: 0    id  days last_scraped  host_since        room_type  \\\n0           1  2515  3130     4/2/2017    9/6/2008     Private room   \n1           2  2595  3127     4/2/2017    9/9/2008  Entire home/apt   \n2           3  3647  3050     4/2/2017  11/25/2008     Private room   \n3           4  3831  3038     4/2/2017   12/7/2008  Entire home/apt   \n4           5  4611  3012     4/2/2017    1/2/2009     Private room   \n\n   bathrooms  bedrooms  price  number_of_reviews  review_scores_cleanliness  \\\n0        1.0       1.0     59                150                        9.0   \n1        1.0       0.0    230                 20                        9.0   \n2        1.0       1.0    150                  0                        NaN   \n3        1.0       1.0     89                116                        9.0   \n4        NaN       1.0     39                 93                        9.0   \n\n   review_scores_location  review_scores_value instant_bookable  \n0                     9.0                  9.0                f  \n1                    10.0                  9.0                f  \n2                     NaN                  NaN                f  \n3                     9.0                  9.0                f  \n4                     8.0                  9.0                t  \nUnnamed: 0                       0\nid                               0\ndays                             0\nlast_scraped                     0\nhost_since                      35\nroom_type                        0\nbathrooms                      160\nbedrooms                        76\nprice                            0\nnumber_of_reviews                0\nreview_scores_cleanliness    10195\nreview_scores_location       10254\nreview_scores_value          10256\ninstant_bookable                 0\ndtype: int64\n         Unnamed: 0            id          days     bathrooms      bedrooms  \\\ncount  40628.000000  4.062800e+04  40628.000000  40468.000000  40552.000000   \nmean   20314.500000  9.698889e+06   1102.368219      1.124592      1.147046   \nstd    11728.437705  5.460166e+06   1383.269358      0.385884      0.691746   \nmin        1.000000  2.515000e+03      1.000000      0.000000      0.000000   \n25%    10157.750000  4.889868e+06    542.000000      1.000000      1.000000   \n50%    20314.500000  9.862878e+06    996.000000      1.000000      1.000000   \n75%    30471.250000  1.466789e+07   1535.000000      1.000000      1.000000   \nmax    40628.000000  1.800967e+07  42828.000000      8.000000     10.000000   \n\n              price  number_of_reviews  review_scores_cleanliness  \\\ncount  40628.000000       40628.000000               30433.000000   \nmean     144.760732          15.904426                   9.198370   \nstd      210.657597          29.246009                   1.119935   \nmin       10.000000           0.000000                   2.000000   \n25%       70.000000           1.000000                   9.000000   \n50%      100.000000           4.000000                  10.000000   \n75%      170.000000          17.000000                  10.000000   \nmax    10000.000000         421.000000                  10.000000   \n\n       review_scores_location  review_scores_value  \ncount            30374.000000         30372.000000  \nmean                 9.413544             9.331522  \nstd                  0.844949             0.902966  \nmin                  2.000000             2.000000  \n25%                  9.000000             9.000000  \n50%                 10.000000            10.000000  \n75%                 10.000000            10.000000  \nmax                 10.000000            10.000000  \n\n\n\n#Convert date columns to datetime\nair['last_scraped'] = pd.to_datetime(air['last_scraped'])\nair['host_since'] = pd.to_datetime(air['host_since'])\n\n\n#Delete issing values and create a new DataFrame \nair2 = air.copy()\nair2['bathrooms'].fillna(air['bathrooms'].median(), inplace=True)\nair2['bedrooms'].fillna(air['bedrooms'].median(), inplace=True)\nair2['review_scores_cleanliness'].fillna(air['review_scores_cleanliness'].mean(), inplace=True)\nair2['review_scores_location'].fillna(air['review_scores_location'].mean(), inplace=True)\nair2['review_scores_value'].fillna(air['review_scores_value'].mean(), inplace=True)\n\n#Remove rows where with null \nair2 = air2[~air2['host_since'].isnull()]\n\nnon_val_air2 = air2.isnull().sum()\n\nnon_val_air2\n\nC:\\Users\\kcrah\\AppData\\Local\\Temp\\ipykernel_21892\\1863144087.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  air2['bathrooms'].fillna(air['bathrooms'].median(), inplace=True)\nC:\\Users\\kcrah\\AppData\\Local\\Temp\\ipykernel_21892\\1863144087.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  air2['bedrooms'].fillna(air['bedrooms'].median(), inplace=True)\nC:\\Users\\kcrah\\AppData\\Local\\Temp\\ipykernel_21892\\1863144087.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  air2['review_scores_cleanliness'].fillna(air['review_scores_cleanliness'].mean(), inplace=True)\nC:\\Users\\kcrah\\AppData\\Local\\Temp\\ipykernel_21892\\1863144087.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  air2['review_scores_location'].fillna(air['review_scores_location'].mean(), inplace=True)\nC:\\Users\\kcrah\\AppData\\Local\\Temp\\ipykernel_21892\\1863144087.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  air2['review_scores_value'].fillna(air['review_scores_value'].mean(), inplace=True)\n\n\nUnnamed: 0                   0\nid                           0\ndays                         0\nlast_scraped                 0\nhost_since                   0\nroom_type                    0\nbathrooms                    0\nbedrooms                     0\nprice                        0\nnumber_of_reviews            0\nreview_scores_cleanliness    0\nreview_scores_location       0\nreview_scores_value          0\ninstant_bookable             0\ndtype: int64\n\n\n\nRegression Model\n\n#Rename columns to remove spaces\nair2.rename(columns={\n    'room_type_Private room': 'room_type_Private_room',\n    'room_type_Shared room': 'room_type_Shared_room'\n}, inplace=True)\n\n\nprint(air2.columns)\n\nIndex(['Unnamed: 0', 'id', 'days', 'last_scraped', 'host_since', 'room_type',\n       'bathrooms', 'bedrooms', 'price', 'number_of_reviews',\n       'review_scores_cleanliness', 'review_scores_location',\n       'review_scores_value', 'instant_bookable'],\n      dtype='object')\n\n\n\n#Rename columns to replace spaces with underscores\nair2.columns = [col.replace(' ', '_') for col in air2.columns]\n\n#Create the model formula based on existing dummy variables\nvariables = ['price', 'days', 'review_scores_cleanliness', 'review_scores_location', 'review_scores_value']\nroom_vars = [col for col in air2.columns if 'room_type_' in col]  \nformula = 'number_of_reviews ~ ' + ' + '.join(variables + room_vars)\n\n#Model\nmodel = smf.glm(formula=formula, data=air2, family=sm.families.Poisson()).fit()\n\nprint(model.summary())\n\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:      number_of_reviews   No. Observations:                40593\nModel:                            GLM   Df Residuals:                    40587\nModel Family:                 Poisson   Df Model:                            5\nLink Function:                    Log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:            -6.7244e+05\nDate:                Wed, 15 May 2024   Deviance:                   1.2209e+06\nTime:                        02:02:12   Pearson chi2:                 1.80e+06\nNo. Iterations:                     6   Pseudo R-squ. (CS):             0.9462\nCovariance Type:            nonrobust                                         \n=============================================================================================\n                                coef    std err          z      P&gt;|z|      [0.025      0.975]\n---------------------------------------------------------------------------------------------\nIntercept                     2.9421      0.017    169.481      0.000       2.908       2.976\nprice                        -0.0003   8.97e-06    -28.218      0.000      -0.000      -0.000\ndays                          0.0006   1.83e-06    328.918      0.000       0.001       0.001\nreview_scores_cleanliness     0.1437      0.002     84.451      0.000       0.140       0.147\nreview_scores_location       -0.1121      0.002    -63.537      0.000      -0.116      -0.109\nreview_scores_value          -0.1217      0.002    -59.861      0.000      -0.126      -0.118\n=============================================================================================\n\n\n\n\nCoefficients\n\nIntercept (3.0353): Shows the log of the expected count of reviews when all other variables are zero.\nRoom Type: Private Room (coef = -0.0822): Private rooms have about 8.22% fewer reviews than entire homes/apartments, holding other factors constant.\n\nShared Room (coef = -0.2291): Shared rooms have about 22.91% fewer reviews compared to entire homes/apartments.\n\nPrice (coef = -0.0004): Each unit increase in price is means a 0.04% decrease in the number of reviews.\nDays (coef = 0.0006): Each additional day a listing is posted means a 0.06% increase in the number of reviews.\nReview Scores: Cleanliness (coef = 0.1422): A one-point increase in the cleanliness score means 14.22% more reviews.\n\nLocation (coef = -0.1142): A higher location score is associated with fewer reviews. Price could be a factor associated with location\nValue (coef = -0.1204): Higher value scores are similarly associated with fewer reviews."
  },
  {
    "objectID": "files/hw2_questions.html",
    "href": "files/hw2_questions.html",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\ntodo: Read in data.\ntodo: Compare histograms and means of number of patents by customer status. What do you observe?\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\ntodo: Compare regions and ages by customer status. What do you observe?\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\ntodo: Write down mathematically the likelihood for \\(Y \\sim \\text{Poisson}(\\lambda)\\). Note that \\(f(Y|\\lambda) = e^{-\\lambda}\\lambda^Y/Y!\\).\ntodo: Code the likelihood (or log-likelihood) function for the Poisson model. This is a function of lambda and Y. For example:\npoisson_loglikelihood &lt;- function(lambda, Y){\n   ...\n}\ntodo: Use your function to plot lambda on the horizontal axis and the likelihood (or log-likelihood) on the vertical axis for a range of lambdas (use the observed number of patents as the input for Y).\ntodo: If you’re feeling mathematical, take the first derivative of your likelihood or log-likelihood, set it equal to zero and solve for lambda. You will find lambda_mle is Ybar, which “feels right” because the mean of a Poisson distribution is lambda.\ntodo: Find the MLE by optimizing your likelihood function with optim() in R or sp.optimize() in Python.\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\ntodo: Update your likelihood or log-likelihood function with an additional argument to take in a covariate matrix X. Also change the parameter of the model from lambda to the beta vector. In this model, lambda must be a positive number, so we choose the inverse link function g() to be exp() so that \\(\\lambda_i = e^{X_i'\\beta}\\). For example:\npoisson_regression_likelihood &lt;- function(beta, Y, X){\n   ...\n}\ntodo: Use your function along with R’s optim() or Python’s sp.optimize() to find the MLE vector and the Hessian of the Poisson model with covariates. Specifically, the first column of X should be all 1’s to enable a constant term in the model, and the subsequent columns should be age, age squared, binary variables for all but one of the regions, and the binary customer variable. Use the Hessian to find standard errors of the beta parameter estimates and present a table of coefficients and standard errors.\ntodo: Check your results using R’s glm() function or Python sm.GLM() function.\ntodo: Interpret the results. What do you conclude about the effect of Blueprinty’s software on patent success?"
  },
  {
    "objectID": "files/hw2_questions.html#blueprinty-case-study",
    "href": "files/hw2_questions.html#blueprinty-case-study",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\ntodo: Read in data.\ntodo: Compare histograms and means of number of patents by customer status. What do you observe?\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\ntodo: Compare regions and ages by customer status. What do you observe?\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\ntodo: Write down mathematically the likelihood for \\(Y \\sim \\text{Poisson}(\\lambda)\\). Note that \\(f(Y|\\lambda) = e^{-\\lambda}\\lambda^Y/Y!\\).\ntodo: Code the likelihood (or log-likelihood) function for the Poisson model. This is a function of lambda and Y. For example:\npoisson_loglikelihood &lt;- function(lambda, Y){\n   ...\n}\ntodo: Use your function to plot lambda on the horizontal axis and the likelihood (or log-likelihood) on the vertical axis for a range of lambdas (use the observed number of patents as the input for Y).\ntodo: If you’re feeling mathematical, take the first derivative of your likelihood or log-likelihood, set it equal to zero and solve for lambda. You will find lambda_mle is Ybar, which “feels right” because the mean of a Poisson distribution is lambda.\ntodo: Find the MLE by optimizing your likelihood function with optim() in R or sp.optimize() in Python.\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\ntodo: Update your likelihood or log-likelihood function with an additional argument to take in a covariate matrix X. Also change the parameter of the model from lambda to the beta vector. In this model, lambda must be a positive number, so we choose the inverse link function g() to be exp() so that \\(\\lambda_i = e^{X_i'\\beta}\\). For example:\npoisson_regression_likelihood &lt;- function(beta, Y, X){\n   ...\n}\ntodo: Use your function along with R’s optim() or Python’s sp.optimize() to find the MLE vector and the Hessian of the Poisson model with covariates. Specifically, the first column of X should be all 1’s to enable a constant term in the model, and the subsequent columns should be age, age squared, binary variables for all but one of the regions, and the binary customer variable. Use the Hessian to find standard errors of the beta parameter estimates and present a table of coefficients and standard errors.\ntodo: Check your results using R’s glm() function or Python sm.GLM() function.\ntodo: Interpret the results. What do you conclude about the effect of Blueprinty’s software on patent success?"
  },
  {
    "objectID": "files/hw2_questions.html#airbnb-case-study",
    "href": "files/hw2_questions.html#airbnb-case-study",
    "title": "Poisson Regression Examples",
    "section": "AirBnB Case Study",
    "text": "AirBnB Case Study\n\nIntroduction\nAirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped of 40,000 Airbnb listings from New York City. The data include the following variables:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n- `id` = unique ID number for each unit\n- `last_scraped` = date when information scraped\n- `host_since` = date when host first listed the unit on Airbnb\n- `days` = `last_scraped` - `host_since` = number of days the unit has been listed\n- `room_type` = Entire home/apt., Private room, or Shared room\n- `bathrooms` = number of bathrooms\n- `bedrooms` = number of bedrooms\n- `price` = price per night (dollars)\n- `number_of_reviews` = number of reviews for the unit on Airbnb\n- `review_scores_cleanliness` = a cleanliness score from reviews (1-10)\n- `review_scores_location` = a \"quality of location\" score from reviews (1-10)\n- `review_scores_value` = a \"quality of value\" score from reviews (1-10)\n- `instant_bookable` = \"t\" if instantly bookable, \"f\" if not\n\n\n\ntodo: Assume the number of reviews is a good proxy for the number of bookings. Perform some exploratory data analysis to get a feel for the data, handle or drop observations with missing values on relevant variables, build one or more models (e.g., a poisson regression model for the number of bookings as proxied by the number of reviews), and interpret model coefficients to describe variation in the number of reviews as a function of the variables provided."
  },
  {
    "objectID": "homeworks/homework3/index.html",
    "href": "homeworks/homework3/index.html",
    "title": "Multinomial Logit Examples",
    "section": "",
    "text": "This assignment uses uses the MNL model to analyze (1) yogurt purchase data made by consumers at a retail location, and (2) conjoint data about consumer preferences for minivans."
  },
  {
    "objectID": "homeworks/homework3/index.html#blueprinty-case-study",
    "href": "homeworks/homework3/index.html#blueprinty-case-study",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty"
  },
  {
    "objectID": "homeworks/homework3/index.html#estimating-yogurt-preferences",
    "href": "homeworks/homework3/index.html#estimating-yogurt-preferences",
    "title": "Multinomial Logit Examples",
    "section": "1. Estimating Yogurt Preferences",
    "text": "1. Estimating Yogurt Preferences\n\nLikelihood for the Multi-nomial Logit (MNL) Model\nSuppose we have \\(i=1,\\ldots,n\\) consumers who each select exactly one product \\(j\\) from a set of \\(J\\) products. The outcome variable is the identity of the product chosen \\(y_i \\in \\{1, \\ldots, J\\}\\) or equivalently a vector of \\(J-1\\) zeros and \\(1\\) one, where the \\(1\\) indicates the selected product. For example, if the third product was chosen out of 4 products, then either \\(y=3\\) or \\(y=(0,0,1,0)\\) depending on how we want to represent it. Suppose also that we have a vector of data on each product \\(x_j\\) (eg, size, price, etc.).\nWe model the consumer’s decision as the selection of the product that provides the most utility, and we’ll specify the utility function as a linear function of the product characteristics:\n\\[ U_{ij} = x_j'\\beta + \\epsilon_{ij} \\]\nwhere \\(\\epsilon_{ij}\\) is an i.i.d. extreme value error term.\nThe choice of the i.i.d. extreme value error term leads to a closed-form expression for the probability that consumer \\(i\\) chooses product \\(j\\):\n\\[ \\mathbb{P}_i(j) = \\frac{e^{x_j'\\beta}}{\\sum_{k=1}^Je^{x_k'\\beta}} \\]\nFor example, if there are 4 products, the probability that consumer \\(i\\) chooses product 3 is:\n\\[ \\mathbb{P}_i(3) = \\frac{e^{x_3'\\beta}}{e^{x_1'\\beta} + e^{x_2'\\beta} + e^{x_3'\\beta} + e^{x_4'\\beta}} \\]\nA clever way to write the individual likelihood function for consumer \\(i\\) is the product of the \\(J\\) probabilities, each raised to the power of an indicator variable (\\(\\delta_{ij}\\)) that indicates the chosen product:\n\\[ L_i(\\beta) = \\prod_{j=1}^J \\mathbb{P}_i(j)^{\\delta_{ij}} = \\mathbb{P}_i(1)^{\\delta_{i1}} \\times \\ldots \\times \\mathbb{P}_i(J)^{\\delta_{iJ}}\\]\nNotice that if the consumer selected product \\(j=3\\), then \\(\\delta_{i3}=1\\) while \\(\\delta_{i1}=\\delta_{i2}=\\delta_{i4}=0\\) and the likelihood is:\n\\[ L_i(\\beta) = \\mathbb{P}_i(1)^0 \\times \\mathbb{P}_i(2)^0 \\times \\mathbb{P}_i(3)^1 \\times \\mathbb{P}_i(4)^0 = \\mathbb{P}_i(3) = \\frac{e^{x_3'\\beta}}{\\sum_{k=1}^Je^{x_k'\\beta}} \\]\nThe joint likelihood (across all consumers) is the product of the \\(n\\) individual likelihoods:\n\\[ L_n(\\beta) = \\prod_{i=1}^n L_i(\\beta) = \\prod_{i=1}^n \\prod_{j=1}^J \\mathbb{P}_i(j)^{\\delta_{ij}} \\]\nAnd the joint log-likelihood function is:\n\\[ \\ell_n(\\beta) = \\sum_{i=1}^n \\sum_{j=1}^J \\delta_{ij} \\log(\\mathbb{P}_i(j)) \\]\n\n\nYogurt Dataset\nWe will use the yogurt_data dataset, which provides anonymized consumer identifiers (id), a vector indicating the chosen product (y1:y4), a vector indicating if any products were “featured” in the store as a form of advertising (f1:f4), and the products’ prices (p1:p4). For example, consumer 1 purchased yogurt 4 at a price of 0.079/oz and none of the yogurts were featured/advertised at the time of consumer 1’s purchase. Consumers 2 through 7 each bought yogurt 2, etc.\n\n\n\n\n\n\nImport Libs\n\n\n\n\n\n\n#Import libarary and data file\nimport pandas as pd\nfrom scipy.stats import ttest_ind\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport math  \nimport scipy.optimize as optimize\nimport scipy.stats as stats\nimport pandas as pd\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nfrom scipy.optimize import minimize\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\n\n\n\n\n\nyog = pd.read_csv(\"C:/Users/kcrah/Desktop/Quarto_stuff/files/yogurt_data.csv\")\n\n\nyog.head()\n\n\n\n\n\n\n\n\n\nid\ny1\ny2\ny3\ny4\nf1\nf2\nf3\nf4\np1\np2\np3\np4\n\n\n\n\n0\n1\n0\n0\n0\n1\n0\n0\n0\n0\n0.108\n0.081\n0.061\n0.079\n\n\n1\n2\n0\n1\n0\n0\n0\n0\n0\n0\n0.108\n0.098\n0.064\n0.075\n\n\n2\n3\n0\n1\n0\n0\n0\n0\n0\n0\n0.108\n0.098\n0.061\n0.086\n\n\n3\n4\n0\n1\n0\n0\n0\n0\n0\n0\n0.108\n0.098\n0.061\n0.086\n\n\n4\n5\n0\n1\n0\n0\n0\n0\n0\n0\n0.125\n0.098\n0.049\n0.079\n\n\n\n\n\n\n\n\n\nyog.describe()\n\n\n\n\n\n\n\n\n\nid\ny1\ny2\ny3\ny4\nf1\nf2\nf3\nf4\np1\np2\np3\np4\n\n\n\n\ncount\n2430.0000\n2430.000000\n2430.000000\n2430.000000\n2430.000000\n2430.000000\n2430.000000\n2430.000000\n2430.000000\n2430.000000\n2430.000000\n2430.000000\n2430.000000\n\n\nmean\n1215.5000\n0.341975\n0.401235\n0.029218\n0.227572\n0.055556\n0.039506\n0.037449\n0.037449\n0.106248\n0.081532\n0.053622\n0.079507\n\n\nstd\n701.6249\n0.474469\n0.490249\n0.168452\n0.419351\n0.229109\n0.194836\n0.189897\n0.189897\n0.020587\n0.011047\n0.008054\n0.007714\n\n\nmin\n1.0000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n-0.012000\n0.000000\n0.025000\n0.004000\n\n\n25%\n608.2500\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.103000\n0.081000\n0.050000\n0.079000\n\n\n50%\n1215.5000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.108000\n0.086000\n0.054000\n0.079000\n\n\n75%\n1822.7500\n1.000000\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.115000\n0.086000\n0.061000\n0.086000\n\n\nmax\n2430.0000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n0.193000\n0.111000\n0.086000\n0.104000\n\n\n\n\n\n\n\n\nFrom the head and describe function we see that the data has transactions from consumers at a yogurt place. The yogurt place has 3 yogurt flavors.\n\n\n\n\n\n\nTODO: reshape and prep the data\n\n\n\n\n\nLet the vector of product features include brand dummy variables for yogurts 1-3 (we’ll omit a dummy for product 4 to avoid multi-collinearity), a dummy variable to indicate if a yogurt was featured, and a continuous variable for the yogurts’ prices:\n\\[ x_j' = [\\mathbbm{1}(\\text{Yogurt 1}), \\mathbbm{1}(\\text{Yogurt 2}), \\mathbbm{1}(\\text{Yogurt 3}), X_f, X_p] \\]\nThe “hard part” of the MNL likelihood function is organizing the data, as we need to keep track of 3 dimensions (consumer \\(i\\), covariate \\(k\\), and product \\(j\\)) instead of the typical 2 dimensions for cross-sectional regression models (consumer \\(i\\) and covariate \\(k\\)).\nWhat we would like to do is reorganize the data from a “wide” shape with \\(n\\) rows and multiple columns for each covariate, to a “long” shape with \\(n \\times J\\) rows and a single column for each covariate. As part of this re-organization, we’ll add binary variables to indicate the first 3 products; the variables for featured and price are included in the dataset and simply need to be “pivoted” or “melted” from wide to long.\n\n\n\nI start by adding binary variables to indicate the first 3 products; and then I “pivoted” and “melted” from a wide dataframe to long dataframe for further data analysis.\n\n#melt to long format\nid_vars = ['id']\nvalue_vars = ['f' + str(j) for j in range(1, 5)] + ['p' + str(j) for j in range(1, 5)] + ['y' + str(j) for j in range(1, 5)]\nyogl = pd.melt(yog, id_vars=id_vars, value_vars=value_vars, var_name='variable', value_name='value')\n\n#split col variable into cols type and product \nyogl['product'] = yogl['variable'].str.extract(r'(\\d+)').astype(int)\nyogl['type'] = yogl['variable'].str.extract(r'([a-z]+)')\n\n#pivot table to organize rows by consumer and product\nyogl = yogl.pivot_table(index=['id', 'product'], columns='type', values='value', aggfunc='first').reset_index()\n\n#create dummy variables for yog1, yog2, yog3\nfor j in range(1, 4):\n    yogl[f'Yogurt_{j}'] = (yogl['product'] == j).astype(int)\n\n#get maximum value for y1, y2, y3, y4 for each consumer\nchoice_columns = ['y1', 'y2', 'y3', 'y4']\nyog['choice'] = (yog[choice_columns] == 1).idxmax(axis=1).str.extract(r'(\\d)').astype(int)\nyogl = yogl.merge(yog[['id', 'choice']], on='id')\nyogl['chosen'] = (yogl['product'] == yogl['choice']).astype(int)\n\nprint(yogl.head())\n\n   id  product    f      p    y  Yogurt_1  Yogurt_2  Yogurt_3  choice  chosen\n0   1        1  0.0  0.108  0.0         1         0         0       4       0\n1   1        2  0.0  0.081  0.0         0         1         0       4       0\n2   1        3  0.0  0.061  0.0         0         0         1       4       0\n3   1        4  0.0  0.079  1.0         0         0         0       4       1\n4   2        1  0.0  0.108  0.0         1         0         0       2       0\n\n\n\n\n\n\n\n\nEstimation\n\n\n\n\n\ntodo: Code up the log-likelihood function.\ntodo: Use optim() in R or optimize() in Python to find the MLEs for the 5 parameters (\\(\\beta_1, \\beta_2, \\beta_3, \\beta_f, \\beta_p\\)). (Hint: you should find 2 positive and 1 negative product intercepts, a small positive coefficient estimate for featured, and a large negative coefficient estimate for price.)\n\n\n\nFirst I coded up the log-likelyhood function for the wide dataframe then I coded up a log-likelyhood for the long dataframe.\n\n#make the feature matrix \nfeature_columns = ['Yogurt_1', 'Yogurt_2', 'Yogurt_3', 'f', 'p']\n\n#make X and convert to float\nX = yogl[feature_columns].astype(float).values  \n\n\nWide Format\n\n#convert data to a single choice index per consumer\ndef convert_choice_data(yog):\n    choice_matrix = yog[['y1', 'y2', 'y3', 'y4']].values\n\n     #index of the chosen product\n    choice_indices = np.argmax(choice_matrix, axis=1) \n    return choice_indices\n\n#convert choice data\nchoice = convert_choice_data(yog) \n\n#negative log likelyhood\ndef neg_log_likelihood(beta, X, choice):\n    utility = X.dot(beta)\n    num_choices = 4\n    num_consumers = len(X) // num_choices\n    utility = utility.reshape(-1, num_choices)\n    exp_utility = np.exp(utility)\n    sum_exp_utility = np.sum(exp_utility, axis=1, keepdims=True)\n    probability = exp_utility / sum_exp_utility\n    log_probability = np.log(probability)\n    log_likelihood = np.sum(log_probability[np.arange(num_consumers), choice])\n    return -log_likelihood \n\nbeta_initial = np.zeros(X.shape[1]) \nresult = minimize(neg_log_likelihood, beta_initial, args=(X, choice), method='BFGS')\n\n\n\nLong Format\n\ndef neg_log_likelihood(beta, X, choice):\n    #get the utility for each product choice\n    utility = X.dot(beta)  \n    num_choices = 4\n    num_consumers = int(len(X) / num_choices) \n\n    #reshape utility to have one row per consumer and one column per choice\n    utility = utility.reshape(num_consumers, num_choices) \n\n    #get probabilities\n    exp_utility = np.exp(utility - np.max(utility, axis=1, keepdims=True))  # For numerical stability\n    sum_exp_utility = np.sum(exp_utility, axis=1, keepdims=True)\n    probability = exp_utility / sum_exp_utility\n\n    # Calculate log-likelihood\n    log_probability = np.log(probability)\n\n    selected_log_prob = log_probability[np.arange(num_consumers), choice.astype(int)]  \n    log_likelihood = np.sum(selected_log_prob)\n\n    #-likelyhood\n    return -log_likelihood \n\nbeta_initial = np.zeros(X.shape[1])  \n\n#optimize\nresult = minimize(neg_log_likelihood, beta_initial, args=(X, choice), method='BFGS')\nprint(\"Estimated coefficients:\", result.x)\n\nEstimated coefficients: [  1.38775541   0.64350486  -3.08611796   0.48741262 -37.05800644]\n\n\n\n\n\n\n\n\nDiscussion\n\n\n\n\n\nWe learn…\ntodo: interpret the 3 product intercepts (which yogurt is most preferred?).\ntodo: use the estimated price coefficient as a dollar-per-util conversion factor. Use this conversion factor to calculate the dollar benefit between the most-preferred yogurt (the one with the highest intercept) and the least preferred yogurt (the one with the lowest intercept). This is a per-unit monetary measure of brand value.\n\n\n\nBased on the wide model and the long model we see what we expected, specifucally there being 2 positive and 1 negative product intercepts, a small positive coefficient estimate for featured, and a large negative coefficient estimate for price.\n\nYogurt 1 (1.39): The positive coefficient means Yogurt 1 is more likely to be chosen when compared.\nYogurt 2 (0.64): The positive coefficient means that Yogurt 2 is also more likely to be chosen when compared.\nYogurt 3 (-3.09): The negative coefficient means that Yogurt 3 is less likely to be chosen when compared.\nFeatured Status (0.49):The positive coefficient means that being featured increases the probability of the yogurt being chosen.\nPrice (-37.06): The large negative coefficient for shows that higher prices significantly decrease the probability of the yogurt being chosen which makes sense.\n\nNext I Found the utility difference, price coefficient and dollar benefit per unit.\n\nestimated_coefficients = np.array([1.38775541, 0.64350486, -3.08611796, 0.48741262, -37.05800644])\n\n#get the intercepts and price coefficient from estimated\nintercepts = estimated_coefficients[:3]  \nprice_coefficient = estimated_coefficients[-1]  \n\n#get the most and least preferred yogs\nmost_preferred_intercept = np.max(intercepts)\nleast_preferred_intercept = np.min(intercepts)\n\n#utility difference\nutility_difference = most_preferred_intercept - least_preferred_intercept\n\n#convert difference to dollar value using the negative price coefficient\ndollar_benefit = utility_difference / -price_coefficient \n\nprint (utility_difference, price_coefficient, dollar_benefit)\n\n4.47387337 -37.05800644 0.12072622895253617\n\n\nAdditionally by using the estimated price coefficient as a dollar-per-util conversion factor we can calculate the dollar benefit between the most-preferred yogurt.\n\nUtility Difference (4.47): The difference between the preferred yogurt (Yogurt 1) and the least-preferred yogurt (Yogurt 3) is 4.47.\nPrice Coefficient (-37.06): This means for every one increase in price, the utl decreases by 37.06.\nDollar Benefit per Unit (0.12): This means that the difference between the most preferred and least preferred yogurt of monetary value is about 12 cents per yogurt.\n\n\nTODO: Adjusted Market Share\n\n\n\n\n\n\nNote\n\n\n\n\n\ntodo: calculate the market shares in the market at the time the data were collected. Then, increase the price of yogurt 1 by $0.10 and use your fitted model to predict p(y|x) for each consumer and each product (this should be a matrix of \\(N \\times 4\\) estimated choice probabilities. Take the column averages to get the new, expected market shares that result from the $0.10 price increase to yogurt 1. Do the yogurt 1 market shares decrease?\n\n\n\nTo calculate the changes that occur if a $0.10 price increase to yogurt A I use the fitted model to predict p(y|x) for each consumer and each product.\n\n#extract columns and normalize price\nfeature_columns = ['Yogurt_1', 'Yogurt_2', 'Yogurt_3', 'f', 'p']\nX = yogl[feature_columns].astype(float).values\nX[:, -1] = (X[:, -1] - np.mean(X[:, -1])) / np.std(X[:, -1])\n\n#number of entries in X is divisible by num_choices\nnum_choices = 4\nnum_consumers = len(X) // num_choices\nchoice = yogl.loc[yogl['chosen'] == 1, 'product'].astype(int).values - 1  \n\ndef neg_log_likelihood(beta, X, choice):\n    utility = X.dot(beta)\n    utility = utility.reshape(-1, num_choices)\n    exp_utility = np.exp(utility - np.max(utility, axis=1, keepdims=True))  # Numerical stability\n    sum_exp_utility = np.sum(exp_utility, axis=1, keepdims=True)\n    probability = exp_utility / sum_exp_utility\n    log_probability = np.log(probability)\n    selected_log_prob = log_probability[np.arange(len(choice)), choice]\n    log_likelihood = np.sum(selected_log_prob)\n    return -log_likelihood  \n\n#initial beta values\nbeta_initial = np.zeros(X.shape[1])\n\n#optimization\nresult = minimize(neg_log_likelihood, beta_initial, args=(X, choice), method='L-BFGS-B', options={'maxiter': 10000, 'disp': True})\nbeta_estimated = result.x\n\n#calculate current market shares\ndef calculate_market_shares(X, beta):\n    utility = X.dot(beta)\n    utility = utility.reshape(-1, num_choices)\n    exp_utility = np.exp(utility - np.max(utility, axis=1, keepdims=True))\n    sum_exp_utility = np.sum(exp_utility, axis=1, keepdims=True)\n    probability = exp_utility / sum_exp_utility\n    market_shares = np.mean(probability, axis=0)\n    return market_shares, probability\n\ncurrent_market_shares, current_probabilities = calculate_market_shares(X, beta_estimated)\nprint(\"Current Market Shares:\", current_market_shares)\n\n#increase the price of yog1 by $0.10 \nX_new = X.copy()\nprice_increase = 0.10 / np.std(yogl['p'])  \nX_new[yogl['product'] == 1, -1] += price_increase\n\n#new market shares \nnew_market_shares, new_probabilities = calculate_market_shares(X_new, beta_estimated)\nprint(\"New Yogurt 1 market share:\", new_market_shares)\n\n#change in market shares\nprint(\"Change in Market Shares:\", new_market_shares - current_market_shares)\n\nCurrent Market Shares: [0.34197542 0.40123472 0.02921837 0.22757149]\nNew Yogurt 1 market share: [0.02111774 0.5911454  0.04404057 0.3436963 ]\nChange in Market Shares: [-0.32085768  0.18991068  0.01482219  0.11612481]\n\n\nChange in Market Shares\n\nYogurt 1: Decreased by 32.09%\nYogurt 2: Increased by 18.99%\nYogurt 3: Increased by 1.48%\n\nFrom the model we can see that if the price of yogurt 1 goes up by $0.10 the market share does decrease by a substanticaal 32%. Subsequently this means that the popularity of yogurt 2 and 3 increases by 19% and 1% respectively. This shows that customers demand of yogurt is elastic."
  },
  {
    "objectID": "homeworks/homework3/index.html#estimating-minivan-preferences",
    "href": "homeworks/homework3/index.html#estimating-minivan-preferences",
    "title": "Multinomial Logit Examples",
    "section": "2. Estimating Minivan Preferences",
    "text": "2. Estimating Minivan Preferences\n\n\n\n\n\n\nData\n\n\n\n\n\ntodo: download the dataset from here: http://goo.gl/5xQObB\ntodo: describe the data a bit. How many respondents took the conjoint survey? How many choice tasks did each respondent complete? How many alternatives were presented on each choice task? For each alternative.\n\n\n\n\nrin = pd.read_csv(\"C:/Users/kcrah/Desktop/Quarto_stuff/files/rintro-chapter13conjoint.csv\")\n\n\nrin.head()\n\n\n\n\n\n\n\n\n\nresp.id\nques\nalt\ncarpool\nseat\ncargo\neng\nprice\nchoice\n\n\n\n\n0\n1\n1\n1\nyes\n6\n2ft\ngas\n35\n0\n\n\n1\n1\n1\n2\nyes\n8\n3ft\nhyb\n30\n0\n\n\n2\n1\n1\n3\nyes\n6\n3ft\ngas\n30\n1\n\n\n3\n1\n2\n1\nyes\n6\n2ft\ngas\n30\n0\n\n\n4\n1\n2\n2\nyes\n7\n3ft\ngas\n35\n1\n\n\n\n\n\n\n\n\n\nrin.describe()\n\n\n\n\n\n\n\n\n\nresp.id\nques\nalt\nseat\nprice\nchoice\n\n\n\n\ncount\n9000.000000\n9000.000000\n9000.000000\n9000.000000\n9000.000000\n9000.000000\n\n\nmean\n100.500000\n8.000000\n2.000000\n6.995444\n35.003889\n0.333333\n\n\nstd\n57.737513\n4.320734\n0.816542\n0.817005\n4.083728\n0.471431\n\n\nmin\n1.000000\n1.000000\n1.000000\n6.000000\n30.000000\n0.000000\n\n\n25%\n50.750000\n4.000000\n1.000000\n6.000000\n30.000000\n0.000000\n\n\n50%\n100.500000\n8.000000\n2.000000\n7.000000\n35.000000\n0.000000\n\n\n75%\n150.250000\n12.000000\n3.000000\n8.000000\n40.000000\n1.000000\n\n\nmax\n200.000000\n15.000000\n3.000000\n8.000000\n40.000000\n1.000000\n\n\n\n\n\n\n\n\n\nrin.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 9000 entries, 0 to 8999\nData columns (total 9 columns):\n #   Column   Non-Null Count  Dtype \n---  ------   --------------  ----- \n 0   resp.id  9000 non-null   int64 \n 1   ques     9000 non-null   int64 \n 2   alt      9000 non-null   int64 \n 3   carpool  9000 non-null   object\n 4   seat     9000 non-null   int64 \n 5   cargo    9000 non-null   object\n 6   eng      9000 non-null   object\n 7   price    9000 non-null   int64 \n 8   choice   9000 non-null   int64 \ndtypes: int64(6), object(3)\nmemory usage: 632.9+ KB\n\n\n\nprint(rin.columns)\n\nIndex(['resp.id', 'ques', 'alt', 'carpool', 'seat', 'cargo', 'eng', 'price',\n       'choice'],\n      dtype='object')\n\n\nThen I found how many respondents took the conjoint survey, how many choice tasks each respondent completed, and lastly how many alternatives were presented on each choice task for each alternative.\n\n#num of respondents\nnum_respondents = rin['resp.id'].nunique()\nprint(f\"Number of respondents: {num_respondents}\")\n\n#num of choice tasks per respondent\nnum_choice_tasks_per_respondent = rin.groupby('resp.id')['ques'].nunique().max()\nprint(f\"Number of choice tasks per respondent: {num_choice_tasks_per_respondent}\")\n\n#alternatives for choice task\nnum_alternatives_per_task = rin.groupby(['resp.id', 'ques']).size().max()\nprint(f\"Number of alternatives per choice task: {num_alternatives_per_task}\")\n\n#alternatives\nalternatives_summary = rin.groupby(['ques', 'alt']).size().reset_index(name='counts')\nprint(alternatives_summary)\n\nNumber of respondents: 200\nNumber of choice tasks per respondent: 15\nNumber of alternatives per choice task: 3\n    ques  alt  counts\n0      1    1     200\n1      1    2     200\n2      1    3     200\n3      2    1     200\n4      2    2     200\n5      2    3     200\n6      3    1     200\n7      3    2     200\n8      3    3     200\n9      4    1     200\n10     4    2     200\n11     4    3     200\n12     5    1     200\n13     5    2     200\n14     5    3     200\n15     6    1     200\n16     6    2     200\n17     6    3     200\n18     7    1     200\n19     7    2     200\n20     7    3     200\n21     8    1     200\n22     8    2     200\n23     8    3     200\n24     9    1     200\n25     9    2     200\n26     9    3     200\n27    10    1     200\n28    10    2     200\n29    10    3     200\n30    11    1     200\n31    11    2     200\n32    11    3     200\n33    12    1     200\n34    12    2     200\n35    12    3     200\n36    13    1     200\n37    13    2     200\n38    13    3     200\n39    14    1     200\n40    14    2     200\n41    14    3     200\n42    15    1     200\n43    15    2     200\n44    15    3     200\n\n\n\nThe number of respondents that took the conjoint survey is 200.\nThe number of choice tasks each respondent completed is 15.\nThe number of alternatives that were presetned is 3.\n\n\n\n\n\n\n\nTODO: Model\n\n\n\n\n\nThe attributes (levels) were number of seats (6,7,8), cargo space (2ft, 3ft), engine type (gas, hybrid, electric), and price (in thousands of dollars).\ntodo: estimate a MNL model omitting the following levels to avoide multicollinearity (6 seats, 2ft cargo, and gas engine). Include price as a continuous variable. Show a table of coefficients and standard errors. You may use your own likelihood function from above, or you may use a function from a package/library to perform the estimation.\n\n\n\nTo estimate a MNL model omitting the following levels to avoide multicollinearity I’ve firsted started with the statsmodels. Unfortunatly I could not get this to work, therefore I decided to use the scikit-learn instead.\nI also got created an accuracy metric and a confusion matrix to gauge how accurate this model is.\n\nsct learn\n\n#reload data\nrin = pd.read_csv(\"C:/Users/kcrah/Desktop/Quarto_stuff/files/rintro-chapter13conjoint.csv\")\n\n#convert and clean \nrin['seat'] = pd.to_numeric(rin['seat'], errors='coerce')\nrin['cargo'] = pd.to_numeric(rin['cargo'], errors='coerce')\nrin['price'] = pd.to_numeric(rin['price'], errors='coerce')\nrin['choice'] = pd.to_numeric(rin['choice'], errors='coerce')\n\nrin = rin.assign(\n    seat=rin['seat'].fillna(rin['seat'].mean()),\n    cargo=rin['cargo'].fillna(rin['cargo'].mean()),\n    price=rin['price'].fillna(rin['price'].mean()),\n    choice=rin['choice'].fillna(rin['choice'].mode()[0]),\n    eng=rin['eng'].fillna('gas')\n)\n\n#create dummy vals\nrin_dummies = pd.get_dummies(rin, columns=['seat', 'cargo', 'eng'], drop_first=True)\n\nexpected_columns = ['seat_7', 'seat_8', 'cargo_3', 'eng_hyb', 'eng_elec', 'price']\nfor col in expected_columns:\n    if col not in rin_dummies.columns:\n        rin_dummies[col] = 0\n\n#Define X and Y\nX = rin_dummies[expected_columns]\ny = rin_dummies['choice']\n\n#standardize \nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n#fit the ML Regression model\nmodel = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\nmodel.fit(X_scaled, y)\n\n#pred\ny_pred = model.predict(X_scaled)\n\n#accuracy \naccuracy = accuracy_score(y, y_pred)\nprint(\"\\nAccuracy:\", accuracy)\n\n#confusionmatrix \ncm = confusion_matrix(y, y_pred)\nprint(\"\\nConfustion Matrix:\",cm)\n\n\nAccuracy: 0.6816666666666666\n\nConfustion Matrix: [[5562  438]\n [2427  573]]\n\n\nUsing that model I got the following results:\n\n\nCoefficients:\n\nseat_7: -0.1127\nseat_8: -0.0618\ncargo_3: 0.0000\neng_hyb: -0.0253\neng_elec: 0.0000\nprice: -0.3006\nIntercepts: -0.3795\nAccuracy: (0.68)\n\n\n\nConfusion Matrix\n\nTrue Negatives: 5562\nFalse Positives: 438\nFalse Negatives: 2427\nTrue Positives: 573\n\nFrom the accuracy matrix we see that the model has 68% accurate.\nFrom the confusion matrix we can see that the model performs well in predicted true negatives but not as well in predicting true positives.\n\n\n\n\n\n\nTODO: Coefficeints and Results\n\n\n\n\n\ntodo: Interpret the coefficients. Which features are more preferred?\ntodo: Use the price coefficient as a dollar-per-util conversion factor. What is the dollar value of 3ft of cargo space as compared to 2ft of cargo space?\n\n\n\n\n\nCoefficients:\n\nseat_7: -0.1127\nseat_8: -0.0618\ncargo_3: 0.0000\neng_hyb: -0.0253\neng_elec: 0.0000\nprice: -0.3006\n\nThe feature that is most prefered is price as its the most significant factor because of the large negative coefficient. This means like the yogurt example, customers have a very elastic demand for the minivan market.\n\n#coefficients\nprice_coefficient = -0.30063783\n\n#cargo_3 coefficient\ncargo3_coefficient = 0.1\n\n#Calculate Dollar Value\ndollar_value_cargo3 = cargo3_coefficient / abs(price_coefficient)\ndollar_value_cargo3\n\n0.3326261369036625\n\n\nThe dollar value of a 3ft cargo space compared to a 2ft cargo space is 0.33.\n\n\n\n\n\n\nTODO: 6 Minivans\n\n\n\n\n\ntodo: assume the market consists of the following 6 minivans. Predict the market shares of each minivan in the market.\n\n\n\nMinivan\nSeats\nCargo\nEngine\nPrice\n\n\n\n\nA\n7\n2\nHyb\n30\n\n\nB\n6\n2\nGas\n30\n\n\nC\n8\n2\nGas\n30\n\n\nD\n7\n3\nGas\n40\n\n\nE\n6\n2\nElec\n40\n\n\nF\n7\n2\nHyb\n35\n\n\n\nhint: this example is taken from the “R 4 Marketing Research” book by Chapman and Feit. I believe the same example is present in the companion book titled “Python 4 Marketing Research”. I encourage you to attempt these questions on your own, but if you get stuck or would like to compare you results to “the answers,” you may consult the Chapman and Feit books.\n\n\n\nTo predict the market shares of each minivan in the market I started by creating the dataframe with the given data.\n\n#create dataframe\nminivans = pd.DataFrame({\n    'Seats': [7, 6, 8, 7, 6, 7],\n    'Cargo': ['2ft', '2ft', '2ft', '3ft', '2ft', '2ft'],\n    'Engine': ['Hyb', 'Gas', 'Gas', 'Gas', 'Elec', 'Hyb'],\n    'Price': [30, 30, 30, 40, 40, 35]\n})\n\n#categorical vals to dummy vals \nminivans_dummies = pd.get_dummies(minivans, columns=['Seats', 'Cargo', 'Engine'], drop_first=True)\n\n#expected columns from minivans dataframe\nexpected_columns = ['seat_7', 'seat_8', 'cargo_3', 'eng_hyb', 'eng_elec', 'price']\n\n#account for missings \nfor col in expected_columns:\n    if col not in minivans_dummies.columns:\n        minivans_dummies[col] = 0\n\n#filter and reorder to match training data\nminivans_dummies = minivans_dummies[expected_columns]\n\n#standardize features\nX_minivans_scaled = scaler.transform(minivans_dummies)\n\n#predict the probabilities\nutilities = model.predict_proba(X_minivans_scaled)\nmarket_shares = np.mean(utilities, axis=0)\n\nminivan_names = ['A', 'B', 'C', 'D', 'E', 'F']\nmarket_shares_chosen = market_shares[1]\nmarket_share_df = pd.DataFrame({'Minivan': minivan_names, 'Market Share': [market_shares_chosen] * len(minivan_names)})\nprint(market_share_df)\n\n  Minivan  Market Share\n0       A      0.990777\n1       B      0.990777\n2       C      0.990777\n3       D      0.990777\n4       E      0.990777\n5       F      0.990777"
  },
  {
    "objectID": "files/hw3_questions.html",
    "href": "files/hw3_questions.html",
    "title": "Multinomial Logit Examples",
    "section": "",
    "text": "This assignment uses uses the MNL model to analyze (1) yogurt purchase data made by consumers at a retail location, and (2) conjoint data about consumer preferences for minivans."
  },
  {
    "objectID": "files/hw3_questions.html#estimating-yogurt-preferences",
    "href": "files/hw3_questions.html#estimating-yogurt-preferences",
    "title": "Multinomial Logit Examples",
    "section": "1. Estimating Yogurt Preferences",
    "text": "1. Estimating Yogurt Preferences\n\nLikelihood for the Multi-nomial Logit (MNL) Model\nSuppose we have \\(i=1,\\ldots,n\\) consumers who each select exactly one product \\(j\\) from a set of \\(J\\) products. The outcome variable is the identity of the product chosen \\(y_i \\in \\{1, \\ldots, J\\}\\) or equivalently a vector of \\(J-1\\) zeros and \\(1\\) one, where the \\(1\\) indicates the selected product. For example, if the third product was chosen out of 4 products, then either \\(y=3\\) or \\(y=(0,0,1,0)\\) depending on how we want to represent it. Suppose also that we have a vector of data on each product \\(x_j\\) (eg, size, price, etc.).\nWe model the consumer’s decision as the selection of the product that provides the most utility, and we’ll specify the utility function as a linear function of the product characteristics:\n\\[ U_{ij} = x_j'\\beta + \\epsilon_{ij} \\]\nwhere \\(\\epsilon_{ij}\\) is an i.i.d. extreme value error term.\nThe choice of the i.i.d. extreme value error term leads to a closed-form expression for the probability that consumer \\(i\\) chooses product \\(j\\):\n\\[ \\mathbb{P}_i(j) = \\frac{e^{x_j'\\beta}}{\\sum_{k=1}^Je^{x_k'\\beta}} \\]\nFor example, if there are 4 products, the probability that consumer \\(i\\) chooses product 3 is:\n\\[ \\mathbb{P}_i(3) = \\frac{e^{x_3'\\beta}}{e^{x_1'\\beta} + e^{x_2'\\beta} + e^{x_3'\\beta} + e^{x_4'\\beta}} \\]\nA clever way to write the individual likelihood function for consumer \\(i\\) is the product of the \\(J\\) probabilities, each raised to the power of an indicator variable (\\(\\delta_{ij}\\)) that indicates the chosen product:\n\\[ L_i(\\beta) = \\prod_{j=1}^J \\mathbb{P}_i(j)^{\\delta_{ij}} = \\mathbb{P}_i(1)^{\\delta_{i1}} \\times \\ldots \\times \\mathbb{P}_i(J)^{\\delta_{iJ}}\\]\nNotice that if the consumer selected product \\(j=3\\), then \\(\\delta_{i3}=1\\) while \\(\\delta_{i1}=\\delta_{i2}=\\delta_{i4}=0\\) and the likelihood is:\n\\[ L_i(\\beta) = \\mathbb{P}_i(1)^0 \\times \\mathbb{P}_i(2)^0 \\times \\mathbb{P}_i(3)^1 \\times \\mathbb{P}_i(4)^0 = \\mathbb{P}_i(3) = \\frac{e^{x_3'\\beta}}{\\sum_{k=1}^Je^{x_k'\\beta}} \\]\nThe joint likelihood (across all consumers) is the product of the \\(n\\) individual likelihoods:\n\\[ L_n(\\beta) = \\prod_{i=1}^n L_i(\\beta) = \\prod_{i=1}^n \\prod_{j=1}^J \\mathbb{P}_i(j)^{\\delta_{ij}} \\]\nAnd the joint log-likelihood function is:\n\\[ \\ell_n(\\beta) = \\sum_{i=1}^n \\sum_{j=1}^J \\delta_{ij} \\log(\\mathbb{P}_i(j)) \\]\n\n\nYogurt Dataset\nWe will use the yogurt_data dataset, which provides anonymized consumer identifiers (id), a vector indicating the chosen product (y1:y4), a vector indicating if any products were “featured” in the store as a form of advertising (f1:f4), and the products’ prices (p1:p4). For example, consumer 1 purchased yogurt 4 at a price of 0.079/oz and none of the yogurts were featured/advertised at the time of consumer 1’s purchase. Consumers 2 through 7 each bought yogurt 2, etc.\ntodo: import the data, maybe show the first few rows, and describe the data a bit.\nLet the vector of product features include brand dummy variables for yogurts 1-3 (we’ll omit a dummy for product 4 to avoid multi-collinearity), a dummy variable to indicate if a yogurt was featured, and a continuous variable for the yogurts’ prices:\n\\[ x_j' = [\\mathbbm{1}(\\text{Yogurt 1}), \\mathbbm{1}(\\text{Yogurt 2}), \\mathbbm{1}(\\text{Yogurt 3}), X_f, X_p] \\]\nThe “hard part” of the MNL likelihood function is organizing the data, as we need to keep track of 3 dimensions (consumer \\(i\\), covariate \\(k\\), and product \\(j\\)) instead of the typical 2 dimensions for cross-sectional regression models (consumer \\(i\\) and covariate \\(k\\)).\nWhat we would like to do is reorganize the data from a “wide” shape with \\(n\\) rows and multiple columns for each covariate, to a “long” shape with \\(n \\times J\\) rows and a single column for each covariate. As part of this re-organization, we’ll add binary variables to indicate the first 3 products; the variables for featured and price are included in the dataset and simply need to be “pivoted” or “melted” from wide to long.\ntodo: reshape and prep the data\n\n\nEstimation\ntodo: Code up the log-likelihood function.\ntodo: Use optim() in R or optimize() in Python to find the MLEs for the 5 parameters (\\(\\beta_1, \\beta_2, \\beta_3, \\beta_f, \\beta_p\\)). (Hint: you should find 2 positive and 1 negative product intercepts, a small positive coefficient estimate for featured, and a large negative coefficient estimate for price.)\n\n\nDiscussion\nWe learn…\ntodo: interpret the 3 product intercepts (which yogurt is most preferred?).\ntodo: use the estimated price coefficient as a dollar-per-util conversion factor. Use this conversion factor to calculate the dollar benefit between the most-preferred yogurt (the one with the highest intercept) and the least preferred yogurt (the one with the lowest intercept). This is a per-unit monetary measure of brand value.\nOne benefit of the MNL model is that we can simulate counterfactuals (eg, what if the price of yogurt 1 was $0.10/oz instead of $0.08/oz).\ntodo: calculate the market shares in the market at the time the data were collected. Then, increase the price of yogurt 1 by $0.10 and use your fitted model to predict p(y|x) for each consumer and each product (this should be a matrix of \\(N \\times 4\\) estimated choice probabilities. Take the column averages to get the new, expected market shares that result from the $0.10 price increase to yogurt 1. Do the yogurt 1 market shares decrease?"
  },
  {
    "objectID": "files/hw3_questions.html#estimating-minivan-preferences",
    "href": "files/hw3_questions.html#estimating-minivan-preferences",
    "title": "Multinomial Logit Examples",
    "section": "2. Estimating Minivan Preferences",
    "text": "2. Estimating Minivan Preferences\n\nData\ntodo: download the dataset from here: http://goo.gl/5xQObB\ntodo: describe the data a bit. How many respondents took the conjoint survey? How many choice tasks did each respondent complete? How many alternatives were presented on each choice task? For each alternative.\nThe attributes (levels) were number of seats (6,7,8), cargo space (2ft, 3ft), engine type (gas, hybrid, electric), and price (in thousands of dollars).\n\n\nModel\ntodo: estimate a MNL model omitting the following levels to avoide multicollinearity (6 seats, 2ft cargo, and gas engine). Include price as a continuous variable. Show a table of coefficients and standard errors. You may use your own likelihood function from above, or you may use a function from a package/library to perform the estimation.\n\n\nResults\ntodo: Interpret the coefficients. Which features are more preferred?\ntodo: Use the price coefficient as a dollar-per-util conversion factor. What is the dollar value of 3ft of cargo space as compared to 2ft of cargo space?\ntodo: assume the market consists of the following 6 minivans. Predict the market shares of each minivan in the market.\n\n\n\nMinivan\nSeats\nCargo\nEngine\nPrice\n\n\n\n\nA\n7\n2\nHyb\n30\n\n\nB\n6\n2\nGas\n30\n\n\nC\n8\n2\nGas\n30\n\n\nD\n7\n3\nGas\n40\n\n\nE\n6\n2\nElec\n40\n\n\nF\n7\n2\nHyb\n35\n\n\n\nhint: this example is taken from the “R 4 Marketing Research” book by Chapman and Feit. I believe the same example is present in the companion book titled “Python 4 Marketing Research”. I encourage you to attempt these questions on your own, but if you get stuck or would like to compare you results to “the answers,” you may consult the Chapman and Feit books."
  },
  {
    "objectID": "homeworks/homework4/index.html",
    "href": "homeworks/homework4/index.html",
    "title": "Key Drivers Analysis",
    "section": "",
    "text": "This post implements a few measure of variable importance, interpreted as a key drivers analysis, for certain aspects of a payment card on customer satisfaction with that payment card.\ntodo: replicate the table on slide 19 of the session 4 slides. This involves calculating pearson correlations, standardized regression coefficients, “usefulness”, Shapley values for a linear regression, Johnson’s relative weights, and the mean decrease in the gini coefficient from a random forest. You may use packages built into R or Python.\nIf you want a challenge, either (1) implement one or more of the measures yourself. “Usefulness” is rather easy to program up. Shapley values for linear regression are a bit more work. Or (2) add additional measures to the table such as the importance scores from XGBoost.\n\n\n\n\n\n\nLoading Libs and Data\n\n\n\n\n\n\n#Import libarary and data file\nimport pandas as pd\nfrom scipy.stats import ttest_ind\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport math  \nimport scipy.optimize as optimize\nimport scipy.stats as stats\nimport pandas as pd\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nfrom scipy.optimize import minimize\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\n\n\ndrive = pd.read_csv(\"C:/Users/kcrah/Desktop/Quarto_stuff/files/data_for_drivers_analysis.csv\")\n\n\n\n\n\n\n\n\n\n\nData Analysis\n\n\n\n\n\n\ndrive.head()\n\n\n\n\n\n\n\n\n\nbrand\nid\nsatisfaction\ntrust\nbuild\ndiffers\neasy\nappealing\nrewarding\npopular\nservice\nimpact\n\n\n\n\n0\n1\n98\n3\n1\n0\n1\n1\n1\n0\n0\n1\n0\n\n\n1\n1\n179\n5\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n2\n1\n197\n3\n1\n0\n0\n1\n1\n1\n0\n1\n1\n\n\n3\n1\n317\n1\n0\n0\n0\n0\n1\n0\n1\n1\n1\n\n\n4\n1\n356\n4\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\n\n\n\n\n\n\n\ndrive.describe()\n\n\n\n\n\n\n\n\n\nbrand\nid\nsatisfaction\ntrust\nbuild\ndiffers\neasy\nappealing\nrewarding\npopular\nservice\nimpact\n\n\n\n\ncount\n2553.000000\n2553.000000\n2553.000000\n2553.000000\n2553.000000\n2553.000000\n2553.000000\n2553.000000\n2553.000000\n2553.000000\n2553.000000\n2553.000000\n\n\nmean\n4.857423\n8931.480611\n3.386604\n0.549550\n0.461810\n0.334508\n0.536232\n0.451234\n0.451234\n0.536232\n0.467293\n0.330983\n\n\nstd\n2.830096\n5114.287849\n1.172006\n0.497636\n0.498637\n0.471911\n0.498783\n0.497714\n0.497714\n0.498783\n0.499027\n0.470659\n\n\nmin\n1.000000\n88.000000\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n25%\n3.000000\n4310.000000\n3.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n50%\n4.000000\n8924.000000\n4.000000\n1.000000\n0.000000\n0.000000\n1.000000\n0.000000\n0.000000\n1.000000\n0.000000\n0.000000\n\n\n75%\n6.000000\n13545.000000\n4.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n\n\nmax\n10.000000\n18088.000000\n5.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000"
  },
  {
    "objectID": "files/hw4_questions.html",
    "href": "files/hw4_questions.html",
    "title": "Key Drivers Analysis",
    "section": "",
    "text": "This post implements a few measure of variable importance, interpreted as a key drivers analysis, for certain aspects of a payment card on customer satisfaction with that payment card.\ntodo: replicate the table on slide 19 of the session 4 slides. This involves calculating pearson correlations, standardized regression coefficients, “usefulness”, Shapley values for a linear regression, Johnson’s relative weights, and the mean decrease in the gini coefficient from a random forest. You may use packages built into R or Python.\nIf you want a challenge, either (1) implement one or more of the measures yourself. “Usefulness” is rather easy to program up. Shapley values for linear regression are a bit more work. Or (2) add additional measures to the table such as the importance scores from XGBoost."
  },
  {
    "objectID": "homeworks/homework5/index.html",
    "href": "homeworks/homework5/index.html",
    "title": "Key Drivers Analysis",
    "section": "",
    "text": "This post implements a few measure of variable importance, interpreted as a key drivers analysis, for certain aspects of a payment card on customer satisfaction with that payment card.\n\n\n\n\n\n\nTODO\n\n\n\n\n\ntodo: replicate the table on slide 19 of the session 4 slides. This involves calculating pearson correlations, standardized regression coefficients, “usefulness”, Shapley values for a linear regression, Johnson’s relative weights, and the mean decrease in the gini coefficient from a random forest. You may use packages built into Python.\nIf you want a challenge, either (1) implement one or more of the measures yourself. “Usefulness” is rather easy to program up. Shapley values for linear regression are a bit more work. Or (2) add additional measures to the table such as the importance scores from XGBoost."
  }
]